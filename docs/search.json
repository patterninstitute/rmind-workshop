[
  {
    "objectID": "tutorial_day1_OLD.html",
    "href": "tutorial_day1_OLD.html",
    "title": "Day1",
    "section": "",
    "text": "How to import datasets into R.\n\nConduct descriptive statistics on the dataset to explore the data.\n\nBasic data visualization with histograms, boxplots, and scatterplots.\n\nHow to calculate the correlation between 2 (numerical) variables.\n\nHow to make a simple linear regression, and plot the line in the scatterplot.\n\nConduct a t-test for basic hypothesis testing.\n\nRecognize the differences between base R plotting and using the ggplots2 package.\n\n\n\n\nThe scientific experiment | Imagine that you are interested in determining the effects of a high-fat diet on gene expression. For this study, the scientists obtained data from 60 mice, where half were fed a lean-diet, and the other half a high-fat diet. All other living conditions were the same. Four weeks after, a biopsy of the mice’s liver was sequenced by RNA-seq, and all mice were weighted, and the sex and age were also recorded. The results from this analysis are saved in diet_mice_metadata.txt file, and the gene counts are in the file diet_mice_counts.xlsx.\n\n\n\n\nWhat is the research question? What is the hypothesis?\nHow many variables are in the study?\nWhich variable(s) are dependent? (Dependent or Response variables are the variables that we are interested in predicting or explaining.)\nWhich variable(s) are independent? (Independent or Explanatory variables are used to explain or predict the dependent variable.)\nWhich variable(s) are covariates? (Covariates are variables that are potentially related to the outcome of interest in a study, but are not the main variable under study - used to control for potential confounding factors in a study.)\nAre the “controls” appropriate? Why?"
  },
  {
    "objectID": "tutorial_day1_OLD.html#basic-data-analysis-lesson-1",
    "href": "tutorial_day1_OLD.html#basic-data-analysis-lesson-1",
    "title": "Day1",
    "section": "",
    "text": "How to import datasets into R.\n\nConduct descriptive statistics on the dataset to explore the data.\n\nBasic data visualization with histograms, boxplots, and scatterplots.\n\nHow to calculate the correlation between 2 (numerical) variables.\n\nHow to make a simple linear regression, and plot the line in the scatterplot.\n\nConduct a t-test for basic hypothesis testing.\n\nRecognize the differences between base R plotting and using the ggplots2 package.\n\n\n\n\nThe scientific experiment | Imagine that you are interested in determining the effects of a high-fat diet on gene expression. For this study, the scientists obtained data from 60 mice, where half were fed a lean-diet, and the other half a high-fat diet. All other living conditions were the same. Four weeks after, a biopsy of the mice’s liver was sequenced by RNA-seq, and all mice were weighted, and the sex and age were also recorded. The results from this analysis are saved in diet_mice_metadata.txt file, and the gene counts are in the file diet_mice_counts.xlsx.\n\n\n\n\nWhat is the research question? What is the hypothesis?\nHow many variables are in the study?\nWhich variable(s) are dependent? (Dependent or Response variables are the variables that we are interested in predicting or explaining.)\nWhich variable(s) are independent? (Independent or Explanatory variables are used to explain or predict the dependent variable.)\nWhich variable(s) are covariates? (Covariates are variables that are potentially related to the outcome of interest in a study, but are not the main variable under study - used to control for potential confounding factors in a study.)\nAre the “controls” appropriate? Why?"
  },
  {
    "objectID": "tutorial_day1_OLD.html#hands-on-exercises",
    "href": "tutorial_day1_OLD.html#hands-on-exercises",
    "title": "Day1",
    "section": "Hands-on exercises",
    "text": "Hands-on exercises\nWe will start by looking at the metadata file containing the variables related to each sample (i.e. each mouse): type of diet, final weight, gender, and age in months.\n\nCreate a new project in RStudio\nStart by creating a new project in RStudio. Go to File &gt; New project, and follow the instructions.\nOnce you have are in the project folder, create a new R script file. Go to File &gt; New File &gt; R Script. A blank text file will appear above the console. Save it in your project folder with the name diet_analysis.R.\n\n\nLoad data and inspect it\n\nDownload the file diet_mice_metadata.txt (mice weights according to diet) from GitHub https://github.com/patterninstitute/rmind-workshop/blob/main/data/diet_mice_metadata.txt.\n\nSave the file in your current working directory where the RProject was created inside a folder named data.\n\nType the instructions inside grey boxes in pane number 2 of RStudio — the R Console. As you already know, the words after a # sign are comments not interpreted by R, so you do not need to copy them.\n\nIn the R console, you must hit enter after each command to obtain the result.\n\nIn the script file (R file), you must run the command by pressing the run button (on the top panel), or by selecting the code you want to run and pressing ctrl + enter.\n\n\nSave all your relevant/final commands (R instructions) to your script file to be available for later use.\n\n\n# Load required packages\nlibrary(tidyverse)     # to ease data wrangling and visualization\nlibrary(here)          # to help with file paths \nlibrary(RColorBrewer)  # color palettes\nlibrary(patchwork)     # combine plots in panels for figures\n\n# Load the file and save it to object mice_data\nmice_data &lt;- read.table(file=here(\"data/diet_mice_metadata.txt\"), \n                        header = TRUE,\n                        sep = \"\\t\", dec = \".\",\n                        stringsAsFactors = TRUE)\n\n\n# Briefly explore the dataset\nView (mice_data)       # Open a tab in RStudio showing the whole table\n\n\nhead (mice_data, 10)   # Show the first 10 rows\n\n   sample_id diet weight gender age_months\n1      mus01 lean  24.02      F         19\n2      mus02 lean  21.79      F         17\n3      mus03 lean  23.90      F         20\n4      mus04 lean  11.15      M         10\n5      mus05 lean  17.73      F         15\n6      mus06 lean  12.89      M         12\n7      mus07 lean  20.12      F         16\n8      mus08 lean  23.04      F         18\n9      mus09 lean  22.84      F         19\n10     mus10 lean  18.92      M         15\n\ntail (mice_data, 10)   # Show the last 10 rows\n\n   sample_id diet weight gender age_months\n51     mus51  fat  23.75      M         18\n52     mus52  fat  21.84      M         17\n53     mus53  fat  26.60      F         20\n54     mus54  fat  21.13      M         17\n55     mus55  fat  24.20      M         19\n56     mus56  fat  30.69      M         23\n57     mus57  fat  23.99      F         18\n58     mus58  fat  19.35      M         17\n59     mus59  fat  26.37      F         22\n60     mus60  fat  28.84      M         20\n\nstr(mice_data)         # Describe the class of each column in the dataset\n\n'data.frame':   60 obs. of  5 variables:\n $ sample_id : Factor w/ 60 levels \"mus01\",\"mus02\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ diet      : Factor w/ 2 levels \"fat\",\"lean\": 2 2 2 2 2 2 2 2 2 2 ...\n $ weight    : num  24 21.8 23.9 11.2 17.7 ...\n $ gender    : Factor w/ 2 levels \"F\",\"M\": 1 1 1 2 1 2 1 1 1 2 ...\n $ age_months: int  19 17 20 10 15 12 16 18 19 15 ...\n\nsummary (mice_data)    # Get the summary statistics for all columns\n\n   sample_id    diet        weight      gender   age_months   \n mus01  : 1   fat :30   Min.   :10.62   F:30   Min.   :10.00  \n mus02  : 1   lean:30   1st Qu.:19.24   M:30   1st Qu.:17.00  \n mus03  : 1             Median :22.79          Median :18.00  \n mus04  : 1             Mean   :22.43          Mean   :17.98  \n mus05  : 1             3rd Qu.:25.63          3rd Qu.:20.00  \n mus06  : 1             Max.   :34.76          Max.   :24.00  \n (Other):54                                                   \n\n\nTo facilitate further analysis, we will create 2 separate data frames: one for each type of diet.\n\n# Filter the diet column by lean or fat and save results in a data frame\nlean &lt;- subset (mice_data, diet == \"lean\")\nfat &lt;- subset (mice_data, diet == \"fat\")\n\n# Look at the new tables\nhead (lean)\n\n  sample_id diet weight gender age_months\n1     mus01 lean  24.02      F         19\n2     mus02 lean  21.79      F         17\n3     mus03 lean  23.90      F         20\n4     mus04 lean  11.15      M         10\n5     mus05 lean  17.73      F         15\n6     mus06 lean  12.89      M         12\n\nhead (fat)\n\n   sample_id diet weight gender age_months\n31     mus31  fat  15.67      F         14\n32     mus32  fat  28.18      M         22\n33     mus33  fat  29.50      M         22\n34     mus34  fat  23.89      M         20\n35     mus35  fat  21.61      F         18\n36     mus36  fat  25.53      M         21\n\n\n\n\n\nDescriptive statistics and Plots using R\nNow, we should look at the distributions of the variables. First we will use descriptive statistics that summarize the sample data. We will use measures of central tendency — Mean, Median, and Mode —, and measures of dispersion (or variability) — Standard Deviation, Variance, Maximum, and Minimum.\n\n# Summary statistics per type of diet - min, max, median, average, standard deviation and variance \nsummary(lean)      # quartiles, median, mean, max and min\n\n   sample_id    diet        weight      gender   age_months   \n mus01  : 1   fat : 0   Min.   :10.62   F:20   Min.   :10.00  \n mus02  : 1   lean:30   1st Qu.:17.86   M:10   1st Qu.:15.00  \n mus03  : 1             Median :20.86          Median :17.00  \n mus04  : 1             Mean   :20.37          Mean   :16.77  \n mus05  : 1             3rd Qu.:23.03          3rd Qu.:18.75  \n mus06  : 1             Max.   :30.12          Max.   :22.00  \n (Other):24                                                   \n\nsd (lean$weight)   # standard deviation of the weight\n\n[1] 4.86655\n\nvar(lean$weight)   # variance of the weight (var=sd^2)\n\n[1] 23.68331\n\nsummary(fat)\n\n   sample_id    diet        weight      gender   age_months   \n mus31  : 1   fat :30   Min.   :15.46   F:10   Min.   :14.00  \n mus32  : 1   lean: 0   1st Qu.:21.71   M:20   1st Qu.:18.00  \n mus33  : 1             Median :24.11          Median :19.00  \n mus34  : 1             Mean   :24.50          Mean   :19.20  \n mus35  : 1             3rd Qu.:27.79          3rd Qu.:20.75  \n mus36  : 1             Max.   :34.76          Max.   :24.00  \n (Other):24                                                   \n\nsd (fat$weight)   \n\n[1] 4.484297\n\nvar(fat$weight)\n\n[1] 20.10892\n\n# The same using tidyverse style programming\nmice_data %&gt;%\n  group_by(diet) %&gt;%\n  summarise(sd = sd(weight))\n\n# A tibble: 2 × 2\n  diet     sd\n  &lt;fct&gt; &lt;dbl&gt;\n1 fat    4.48\n2 lean   4.87\n\n\n\n\n\nHow is the variable “mouse weight” distributed in each diet? | Histograms\nAfter summarizing the data, we should find appropriate plots to look at it. A first approach is to look at the frequency of the mouse weight values per diet using a histogram.\nRecall | Histograms plot the distribution of a continuous variable (x-axis), in which the data is divided into a set of intervals (or bins), and the count (or frequency) of observations falling into each bin is plotted as the height of the bar.\n\n# Histogram using base R plotting functions\nhist(lean$weight,\n     xlab = \"Mouse weight\",                         \n     main = \"Lean Diet | Histogram of mouse weight\", \n     col = brewer.pal(5, \"YlOrRd\"))   # using 5 colors of the Yellow to Red palette\n\n\n\n# Make the same plot for the fat diet, using our own colors\n   # to see the other color names: colors()\nhist(fat$weight,\n     xlab = \"Mouse weight\",\n     main = \"Fat Diet | Histogram of mouse weight\", \n      col = brewer.pal(5, \"Greens\"))\n\n\n\n# Plot both histograms in same image\npar(mfrow=c(1,2))   # set the parameters for the number of rows and columns of plots\n\nhist(lean$weight, col = brewer.pal(5, \"YlOrRd\"),\n     xlab = \"Mouse weight\",                            \n     main = \"Lean Diet | Histogram of weight\")\n\nhist(fat$weight,\n     xlab = \"Mouse weight\",\n     main = \"Fat Diet | Histogram of weight\", \n     col = brewer.pal(5, \"Greens\"))\n\n\n\n# Similar plot, but using ggplot2\nmice_data %&gt;%\n  filter(diet == \"lean\") %&gt;%\n  ggplot(mapping = aes(weight)) +\n  geom_histogram(binwidth = 1, fill = \"seagreen3\" ) -&gt; p_hist_lean\n\nmice_data %&gt;%\n  filter(diet == \"fat\") %&gt;%\n  ggplot(mapping = aes(weight)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\") -&gt; p_hist_fat\n\np_hist_lean + p_hist_fat\n\n\n\n\n\n\n\nHow is the variable “mouse weight” distributed in each diet? | Boxplots\nSince our data of interest is one categorical variable (type of diet), and one continuous variable (weight), a boxplot is one of the most informative.\nNote | A boxplot represents the distribution of a continuous variable. The box in the middle represents the interquartile range (IQR), which is the range of values from the first quartile to the third quartile, and the line inside the box represents the median value (i.e. the second quartile). The lines extending from the box are called whiskers, and represent the range of the data outside the box, i.e. the maximum and the minimum, excluding any outliers, which are shown as points outside the whiskers (not present in this dataset). Outliers are defined as values that are more than 1.5 times the IQR below the first quartile or above the third quartile.\n\n# Box and whiskers plot \nboxplot(lean$weight, fat$weight, col=c(\"lightpink\", \"lightgreen\"),\n        names=c(\"Lean diet\", \"Fat diet\"),\n        ylab=\"Mouse weight (g)\",\n        ylim = c(5, 40))   # setting the limits of the y axis\n\n# Plot individual points and add them to the boxplot\n   # pch is the point character, i.e. the symbol used for the points\nstripchart(list(lean$weight, fat$weight),\n           vertical = TRUE, method = \"stack\",\n           pch = 21, col=\"grey42\", bg=\"lightgrey\",  \n           add = TRUE)\n\n\n\n# Similar, but using ggplo2\nmice_data %&gt;%\n  ggplot(mapping=(aes(x=diet,y=weight))) +\n  geom_boxplot(aes(fill=diet)) +\n  geom_jitter(width=0.1, size=2, alpha=0.6)\n\n\n\n\n\n\nHow are the other variables distributed?\nThere are other variables in our data for each mouse that could influence the results, namely gender (categorical variable) and age (discrete variable). We should also look at these data.\n\n# create table with weights per gender\nfemales &lt;- subset (mice_data, gender == \"F\")\nmales &lt;- subset (mice_data, gender == \"M\")\n\n# Box and whiskers plot\nboxplot(lean$weight, fat$weight, females$weight, males$weight,\n        ylim = c(5, 40),\n        col=c(\"lightpink\", \"lightgreen\", \"skyblue\", \"orange\"),\n        names=c(\"Lean diet\", \"Fat diet\", \"Females\", \"Males\"),\n        ylab=\"Mouse weight (g)\", main = \"Boxplot of mice weight\")\n\n# Plot individual points and add them to the boxplot\nstripchart(list(lean$weight, fat$weight, females$weight, males$weight),\n           vertical = TRUE, method = \"jitter\",\n           pch = 21, col=\"grey42\", bg=\"grey80\",\n           add = TRUE)\n\n\n\n# Look at the distribution of age\nhist(mice_data$age_months, \n     xlab=\"Age (months)\", \n     col = brewer.pal(5, \"Pastel1\"),\n     main=\"Histogram of mice age\")\n\n\n\n# Similar, but using ggplot and an interaction term (which is what we are really interested in looking at)\nmice_data %&gt;%\n  ggplot(mapping = aes(x=interaction(diet,gender),y=weight)) +\n  geom_boxplot(aes(fill=interaction(diet,gender))) +\n  geom_jitter(width=0.1, size=2, alpha=0.6)\n\n\n\n# What if we want violin plots?\nmice_data %&gt;%\n  ggplot(mapping = aes(x=interaction(diet,gender),y=weight)) +\n  geom_violin(aes(fill=interaction(diet,gender))) +\n  geom_jitter(width=0.1, size=2, alpha=0.6)\n\n\n\n\n\n\nWhat is the frequency of each variable?\nWhen exploring the results of an experiment, we want to learn about the variables measured (age, gender, weight), and how many observations we have for each variable (number of females, number of males …), or combination of variables, for example, number of females in lean diet. This is easily done by using the R base function table. This function outputs a frequency table, i.e. the frequency (counts) of all combinations of the variables of interest.\n\n# How many measurements do we have for each gender (a categorical variable)\ntable(mice_data$gender)\n\n\n F  M \n30 30 \n\n# How many measurements do we have for each diet (a categorical variable)\ntable(mice_data$diet)\n\n\n fat lean \n  30   30 \n\n# How many measurements do we have for each gender in each diet? (Count the number of observations in the combination between the two categorical variables).\ntable(mice_data$diet, mice_data$gender)\n\n      \n        F  M\n  fat  10 20\n  lean 20 10\n\n# We can also use this for numerical discrete variables, like age.\n# How many measurements of each age (a discrete variable) do we have by gender? \ntable(mice_data$age_months, mice_data$gender)\n\n    \n     F M\n  10 1 1\n  12 0 2\n  14 3 0\n  15 3 2\n  16 1 0\n  17 7 5\n  18 4 5\n  19 4 3\n  20 3 4\n  21 1 3\n  22 3 3\n  23 0 1\n  24 0 1\n\n# And by diet type? \ntable(mice_data$age_months, mice_data$diet)\n\n    \n     fat lean\n  10   0    2\n  12   0    2\n  14   2    1\n  15   1    4\n  16   0    1\n  17   3    9\n  18   6    3\n  19   4    3\n  20   6    1\n  21   1    3\n  22   5    1\n  23   1    0\n  24   1    0\n\n# What if we want to know the results for each of the three variables: age, diet and gender?\n   # Using ftable instead of table to format the output in a more friendly way\nftable(mice_data$age_months, mice_data$diet, mice_data$gender)\n\n         F M\n            \n10 fat   0 0\n   lean  1 1\n12 fat   0 0\n   lean  0 2\n14 fat   2 0\n   lean  1 0\n15 fat   1 0\n   lean  2 2\n16 fat   0 0\n   lean  1 0\n17 fat   0 3\n   lean  7 2\n18 fat   2 4\n   lean  2 1\n19 fat   1 3\n   lean  3 0\n20 fat   2 4\n   lean  1 0\n21 fat   0 1\n   lean  1 2\n22 fat   2 3\n   lean  1 0\n23 fat   0 1\n   lean  0 0\n24 fat   0 1\n   lean  0 0\n\n# Doing a similar analysis, using tidyverse programming style\nmice_data %&gt;%\n  group_by(age_months, diet, gender) %&gt;%\n  count()\n\n# A tibble: 30 × 4\n# Groups:   age_months, diet, gender [30]\n   age_months diet  gender     n\n        &lt;int&gt; &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;\n 1         10 lean  F          1\n 2         10 lean  M          1\n 3         12 lean  M          2\n 4         14 fat   F          2\n 5         14 lean  F          1\n 6         15 fat   F          1\n 7         15 lean  F          2\n 8         15 lean  M          2\n 9         16 lean  F          1\n10         17 fat   M          3\n# ℹ 20 more rows\n\n\n\n\n\nBivariate Analysis | Linear regression and Correlation coefficient\nIs there a dependency between the age and the weight of the mice in our study?\nTo test if two variables are correlated we will start by (1) making a scatter plot of these two variables, followed by a calculation of the Pearson correlation coefficient, and finally by fitting a linear model to the data to evaluate how the weight changes depending on the age of the mice.\n\n# Create the vectors with the variables of interest\nmy.weight &lt;- mice_data$weight \nmy.age &lt;- mice_data$age_months\n\n# Step1: scatter plot of age and weight \n# Note that the dependent variable is the weight, so it should be in the y axis, while the independent variable should be in the x axis.\nplot(mice_data$age_months, mice_data$weight,\n     ylab = \"Weight (g)\",\n     xlab = \"Age (months)\", \n     pch = 19)  # character used for the points\n\n\n\n# Step2: Calculate the Pearson coefficient of correlation (r)\nmy.correlation &lt;- cor(my.weight, my.age, method = \"pearson\")\nmy.correlation\n\n[1] 0.9539404\n\n# Step3: fit a linear model (using the function lm) and \n# draw it on the scatter plot (using the function abline)\n  # NOTE: \"my.weight ~ my.age\" can be read as \"my.weight is modeled as a function of my.age\" or \n  # \"my.weight is explained by my.age\".\n  # When using lm() for linear regression, the \"y ~ x\" formula indicates that \n  # y is the dependent variable and x is the independent variable.\n\nmy.lm &lt;- lm (my.weight ~ my.age)\n\n# Plot the fitted line on the scatter plot\nplot(mice_data$age_months, mice_data$weight, \n     ylab = \"Weight (g) [Dependent variable]\", xlab = \"Age (months) [Independent variable]\", pch = 19, \n     col = c(rep(\"lightgreen\", 30), rep(\"orange\", 30)))   # color the points from lean and fat diet\n\n# add the line to the plot\nabline(my.lm, col=\"grey50\", lwd=2)\n\n# add a legend to the plot\nlegend(30, 14, legend=c(\"Lean diet\", \"Fat diet\"),\n       col=c(\"lightgreen\", \"orange\"), pch=19)\n\n\n\n# Similar visualiztion using ggplot\nmice_data %&gt;%\n  ggplot(mapping = aes(x=age_months,y=weight))+\n  geom_point(aes(fill=diet), shape=21, size=2) +\n  geom_smooth(method = \"lm\", se=TRUE, color=\"grey30\") # se is the shaded confidence interval\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n# Now making a linear fit per diet type\nmice_data %&gt;%\n  ggplot(mapping = aes(x=age_months,y=weight))+\n  geom_point(aes(fill=diet), shape=21, size=2) +\n  geom_smooth(aes(group=diet, color=diet),method = \"lm\", se=FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nHypothesis testing and Statistical significance using R\nGoing back to our original question: Does the type of diet influence the body weight of mice?\nCan we answer this question just by looking at the plot? Are these observations compatible with a scenario where the type of diet does not influence body weight?\nRemember the basic statistical methods:\n\nHere enters hypothesis testing. In hypothesis testing, the investigator formulates a null hypothesis (H0) that usually states that there is no difference between the two groups, i.e. the observed weight differences between the two groups of mice occurred only due to sampling fluctuations (like when you repeat an experiment drawing samples from the same population). In other words, H0 corresponds to an absence of effect.\nThe alternative hypothesis (H1), just states that the effect is present between the two groups, i.e. that the samples were taken from different populations.\nHypothesis testing proceeds with using a statistical test to try and reject H0. For this experiment, we will use a T-test that compares the difference between the means of the two diet groups, yielding a p-value that we will use to decide if we reject the null hypothesis, at a 5% significance level (p-value &lt; 0.05). Meaning that, if we repeat this experiment 100 times in different mice, in 5 of those experiments we will reject the null hypothesis, even thought the null hypothesis is true.\n\n# Apply a T-test to the lean and fat diet weights \n\n### Explanation of the arguments used ###\n  # alternative=\"two.sided\" :  two-sided because we want to test any difference between the means, and not only weight gain or weight loss (in which case it would be a one-sided test)\n\n  # paired = FALSE : because we measured the weight in 2 different groups of mice (never the same individual). If we measure a variable 2 times in the same individual the data would be paired.\n\n  # var.equal = TRUE : T-tests apply to equal variance data, so we assume it is TRUE and ask R to estimate the variance (if we chose FALSE, then R uses another similar method called Welch (or Satterthwaite) approximation) \n\nttest &lt;- t.test(lean$weight, fat$weight,\n                alternative=\"two.sided\", \n                paired = FALSE, \n                var.equal = TRUE)\n\n# Print the results\nttest\n\n\n    Two Sample t-test\n\ndata:  lean$weight and fat$weight\nt = -3.4197, df = 58, p-value = 0.001154\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.550137 -1.713197\nsample estimates:\nmean of x mean of y \n 20.36700  24.49867 \n\n\n\n\n\nNow that we have calculated the T-test, shall we accept or reject the null hypothesis? What are the outputs in R from the t-test?\n\n# Find the names of the output from the function t.test\nnames(ttest)\n\n [1] \"statistic\"   \"parameter\"   \"p.value\"     \"conf.int\"    \"estimate\"   \n [6] \"null.value\"  \"stderr\"      \"alternative\" \"method\"      \"data.name\"  \n\n# Extract just the p-value\nttest$p.value\n\n[1] 0.00115364\n\n\n\n\n\nFinal discussion\n\n\nTake some time to discuss the results with the other participants, and decide if H0 should be rejected or not, and how confident you are that your decision is reasonable. Can you propose solutions to improve your confidence on the results? Is the experimental design appropriate for the research question being asked? Is this experiment well controlled and balanced?"
  },
  {
    "objectID": "contacts.html",
    "href": "contacts.html",
    "title": "Contacts",
    "section": "",
    "text": "Ramiro Magno\n\n\n\n\n\n\n\nIsabel Duarte"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "R-Mind",
    "section": "",
    "text": "The ESN-ISN Neurochemistry School 2023, scheduled from October 29th to November 4th, 2023, in Faro, Algarve, aims to provide an advanced educational platform focused on the molecular mechanisms underpinning neurodegeneration, and advanced therapies targeted towards them.\nThe program comprises lectures, workshops, and hands-on lab sessions, in a collaborative environment, where attendees from various countries are encouraged to exchange knowledge and expand their network of neuroscience researchers.\nThe event will be hosted at the Algarve Biomedical Center Research Institute and the Faculty of Medicine and Biomedical Sciences, located within the University of Algarve Gambelas campus."
  },
  {
    "objectID": "1_swirl_tutorial.html",
    "href": "1_swirl_tutorial.html",
    "title": "R4AB | Swirl tutorial",
    "section": "",
    "text": "The swirl package is an interactive, self-paced, hands-on tutorial. You will learn R inside R. For more info about this package, visit: https://swirlstats.com/\n\n\nTo start open RStudio. This is an Integrated Development Environment - IDE - that includes syntax-highlighting text editor (1 in Figure1), an R console to execute code (2 in Figure1), as well as workspace and history management (3 in Figure1), and tools for plotting and exporting images, browsing the workspace, managing packages and viewing html/pdf files created within RStudio (4 in Figure1).\n\n\n\nFigure 1: RStudio Graphical User Interface (GUI)\n\n\n\n\n\nType these instructions in the R console (panel 2 in Figure 1).\nThe words after a # sign are called comments, and are not interpreted by R, so you do not need to copy them.\nYou can copy-paste the code, and press enter after each command.\ninstall.packages(\"swirl\")   # Install swirl\n\nlibrary(\"swirl\")            # Load the swirl package to make it available for you to use\n\nswirl()                     # Start swirl\nAfter starting swirl, follow the instructions given by the program, and complete all of the following lessons:\nPlease install the course:\n1: R Programming: The basics of programming in R\nChoose the course:\n1: R Programming\nComplete the following lessons, in this order:\n1: Basic Building Blocks\n2: Workspace and Files\n3: Sequences of Numbers\n4: Vectors\n5: Missing Values\n6: Subsetting Vectors\n7: Matrices and Data Frames\n8: Logic\n9: Functions\n12: Looking at Data\n15: Base Graphics\nNow, just Keep Calm… and Good Work!\n\n\n\n\nAfter finishing the introduction to R with swirl, please recall the following information and hints about R and R programming.\n\nR is case sensitive - be aware of capital letters (b is different from B).\nAll R code lines starting with the # (hash) sign are interpreted as comments, and therefore not evaluated.\n\n\n\n# This is a comment\n# 3 + 4   # this code is not evaluated, so and it does not print any result\n2 + 3     # the code before the hash sign is evaluated, so it prints the result (value 5)\n\n[1] 5\n\n\n\nExpressions in R are evaluated from the innermost parenthesis toward the outermost one (following proper mathematical rules).\n\n\n# Example with parenthesis:\n((2+2)/2)-2\n\n[1] 0\n\n# Without parenthesis:\n2+2/2-2\n\n[1] 1\n\n\n\nSpaces in variable names are not allowed — use a dot . or underscore _ to create longer names to make the variables more descriptive, e.g. my.variable_name.\n\nSpaces between variables and operators do not matter: 3+2 is the same as 3 + 2, and function (arg1 , arg2) is the same as function(arg1,arg2).\n\nA new line (enter) ends one command in R. If you want to write 2 expressions/commands in the same line, you have to separate them by a ; (semi-colon).\n\n\n#Example:\n3 + 2 ; 5 + 1  \n\n[1] 5\n\n\n[1] 6\n\n\n\nTo access the help pages on R functions, just type help(function_name) or ?function_name.\n\n# Example: open the documentation about the function sum\nhelp (sum)    \n# Quick access to help page about sum\n?sum          \n\nRStudio auto-completes your commands by showing you possible alternatives as soon as you type 3 consecutive characters. If you want to see the options for less than 3 chars to get help on available functions, just press tab to display available options. Tip: Use auto-complete as much as possible to avoid typing mistakes.\nThere are 4 main vector data types in R: Logical (TRUE or FALSE); Numeric (e.g. 1,2,3…); Character (i.e. text, for example “u”, “alg”, “arve”) and Complex (e.g. 3+2i).\nVectors are ordered sets of elements. In R vectors are 1-based, i.e. the first index position is number 1 (as opposed to other programming languages whose indexes start at zero, like Python).\nR objects can be divided in two main groups: Functions and Data-related objects. Functions receive arguments inside circular brackets ( ) and objects receive arguments inside square brackets [ ]:\nfunction (arguments)\ndata.object [arguments]\nThere are five basic data structures in R: Vector, Matrix, Array, Data frame, and List (see following figure):\n\n\n12.1 The basic data structure in R is the vector, which requires all of its elements to be of the same type (e.g. all numeric; all character (text); all logical (TRUE or FALSE)).\n12.2 Matrices are two dimensional vectors (tables), where all columns are of the same length, and all from the same type.\n12.3 Data frames are the most flexible and commonly used R data structures, used to store datasets in spreadsheet-like tables. The columns can be vectors of different types (i.e. text, number, logical, etc, can all be stored in the same data frame), but each column must to be of the same data type.\n12.4 Lists are ordered sets of elements, that can be arbitrary R objects (vectors, data frames, matrices, strings, functions, other lists etc), and heterogeneous, i.e. each element can be of a different type and different lengths.\n\nR is column-major by default, meaning that the elements of a multi-dimensional array are linearly stored in memory column-wise. This is important for example when using data to populate a matrix.\n\n\nmatrix(1:9, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\nWhen subsetting matrices and data-frames, the first index is the row, and the second index is the column. If left empty (no value), then the full row or the full column is returned.\n\n\n# My letters matrix\n(my_letters &lt;- matrix(rep(LETTERS[1:3], each=3), ncol = 3))\n\n     [,1] [,2] [,3]\n[1,] \"A\"  \"B\"  \"C\" \n[2,] \"A\"  \"B\"  \"C\" \n[3,] \"A\"  \"B\"  \"C\" \n\n# Element in Row 1, Column 2\nmy_letters[1,2]\n\n[1] \"B\"\n\n# Element in Row 2, Column 3\nmy_letters[2,3]\n\n[1] \"C\"\n\n# Row 3\nmy_letters[3,]\n\n[1] \"A\" \"B\" \"C\"\n\n# Column 1\nmy_letters[,1]\n\n[1] \"A\" \"A\" \"A\"\n\n\n\n\n\nThe working directory is the location in the filesystem (folder) where R will look for input data and where it will save the output from your analysis. In RStudio you can graphically check this information.\ndir()   # list all files in your working directory\ngetwd() # find out the path to your working directory\nsetwd(\"/home/isabel\") # example of setting a new working directory path\n\n\n\nThe R environment is controlled by hidden files (files that start with a dot .) in the start-up directory: .RData, .Rhistory and .Rprofile (optional).\n\n.RData is a file containing all the objects, data, and functions created during a work-session. This file can then be loaded for future work without requiring the re-computation of the analysis. (Note: it can potentially be a very large file);\n\n.Rhistory saves all commands that have been typed during the R session;\n.Rprofile useful for advanced users to customize RStudio behavior.\n\nThese files can be renamed:\n# DO NOT RUN\nsave.image (file=\"myProjectName.RData\")\nsavehistory (file=\"myProjectName.Rhistory\")\n\nTo quit R just close RStudio, or use the q () function. You will then be asked if you want to save the workspace image (i.e. the .RData file):\nq()\nSave workspace image to ~/path/to/your/working/directory/.RData? [y/n/c]:\nIf you type y (yes), then the entire R workspace will be written to the .RData file (which can be very large). Often it is sufficient to just save an analysis script (i.e. a reproducible protocol) in an R source file. This way, one can quickly regenerate all data sets and objects for future analysis. The .RData file is particularly useful to save the results from analyses that require a long time to compute.\nIn RStudio, to quit your session, just hit the close button (x button), just like when you want to quit any other application in your computer.\nIn RStudio Server, you must log out of your account. When you log back in, your session will resume.\n\n\n\n\nIn R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. These packages are stored in online repositories from which they can be easily retrieved and installed on your computer (R packages by Hadley Wickham). There are 2 main R repositories:\n\nThe Comprehensive R Archive Network - CRAN (18927 packages in March 2022)\n\nBioconductor (2083 packages in March 2022) (bioscience data analysis)\n\nThis huge variety of packages is one of the reasons why R is so successful: the chances are that someone has already developed a method to solved the problem that you’re working on, and you can benefit from their work by downloading their package for free.\nIn this course, we will not use many packages. However, if you continue to use R for your data analyses you will need to install many more useful packages, particularly from Bioconductor — an open source, open development software project to provide tools for the analysis and comprehension of high-throughput genomics data […] based primarily on the R programming language.\n\n\n\n\nThere are several alternative ways to install packages in R. Depending on the repository from which you want to install a package, there are dedicated functions that facilitate this task:\n\ninstall.packages() built-in function to install packages from the CRAN repository;\nBiocManager::install() to install packages from the Bioconductor repository;\nremotes::install_github to install packages from GitHub (a code repository, not exclusively dedicated to R).\n\nAfter installing a package, you must load it to make its contents (functions and/or data) available. The loading is done with the function library(). Alternatively, you can prepend the name of the package followed by :: to the function name to use it (e.g. ggplot2::qplot()).\ninstall.packages(\"ggplot2\")   # install the package called ggplot2 from CRAN\nlibrary (\"ggplot2\")            # load the library ggplot2 \n\nhelp (package=ggplot2)         # help(package=\"package_name\") to get help about a specific package\nvignette (\"ggplot2\")           # show a pdf with the package manual (called R vignettes)\n\n\n\n\nRStudio Projects are a great functionality, easing the transition between dataset analyses, and allowing a fast navigation to your analysis/working directory. To create a new project:\nFile &gt; New Project... &gt; New Directory &gt; New Project\nDirectory name: compBiol_module1\nCreate project as a subdirectory of: ~/\n                           Browse... (directory/folder to save the class data)\nCreate Project\nProjects should be personalized by clicking on the menu in the right upper corner. The general options - R General - are the most important to customize, since they allow the definition of the RStudio “behavior” when the project is opened. The following suggestions are particularly useful:\nRestore .RData at startup - Yes (for analyses with +1GB of data, you should choose \"No\")\nSave .RData on exit - Ask\nAlways save history - Yes\n\n\n\nFigure 2: Customize Project"
  },
  {
    "objectID": "1_swirl_tutorial.html#using-the-swirl-package-tutorial",
    "href": "1_swirl_tutorial.html#using-the-swirl-package-tutorial",
    "title": "R4AB | Swirl tutorial",
    "section": "",
    "text": "The swirl package is an interactive, self-paced, hands-on tutorial. You will learn R inside R. For more info about this package, visit: https://swirlstats.com/\n\n\nTo start open RStudio. This is an Integrated Development Environment - IDE - that includes syntax-highlighting text editor (1 in Figure1), an R console to execute code (2 in Figure1), as well as workspace and history management (3 in Figure1), and tools for plotting and exporting images, browsing the workspace, managing packages and viewing html/pdf files created within RStudio (4 in Figure1).\n\n\n\nFigure 1: RStudio Graphical User Interface (GUI)\n\n\n\n\n\nType these instructions in the R console (panel 2 in Figure 1).\nThe words after a # sign are called comments, and are not interpreted by R, so you do not need to copy them.\nYou can copy-paste the code, and press enter after each command.\ninstall.packages(\"swirl\")   # Install swirl\n\nlibrary(\"swirl\")            # Load the swirl package to make it available for you to use\n\nswirl()                     # Start swirl\nAfter starting swirl, follow the instructions given by the program, and complete all of the following lessons:\nPlease install the course:\n1: R Programming: The basics of programming in R\nChoose the course:\n1: R Programming\nComplete the following lessons, in this order:\n1: Basic Building Blocks\n2: Workspace and Files\n3: Sequences of Numbers\n4: Vectors\n5: Missing Values\n6: Subsetting Vectors\n7: Matrices and Data Frames\n8: Logic\n9: Functions\n12: Looking at Data\n15: Base Graphics\nNow, just Keep Calm… and Good Work!\n\n\n\n\nAfter finishing the introduction to R with swirl, please recall the following information and hints about R and R programming.\n\nR is case sensitive - be aware of capital letters (b is different from B).\nAll R code lines starting with the # (hash) sign are interpreted as comments, and therefore not evaluated.\n\n\n\n# This is a comment\n# 3 + 4   # this code is not evaluated, so and it does not print any result\n2 + 3     # the code before the hash sign is evaluated, so it prints the result (value 5)\n\n[1] 5\n\n\n\nExpressions in R are evaluated from the innermost parenthesis toward the outermost one (following proper mathematical rules).\n\n\n# Example with parenthesis:\n((2+2)/2)-2\n\n[1] 0\n\n# Without parenthesis:\n2+2/2-2\n\n[1] 1\n\n\n\nSpaces in variable names are not allowed — use a dot . or underscore _ to create longer names to make the variables more descriptive, e.g. my.variable_name.\n\nSpaces between variables and operators do not matter: 3+2 is the same as 3 + 2, and function (arg1 , arg2) is the same as function(arg1,arg2).\n\nA new line (enter) ends one command in R. If you want to write 2 expressions/commands in the same line, you have to separate them by a ; (semi-colon).\n\n\n#Example:\n3 + 2 ; 5 + 1  \n\n[1] 5\n\n\n[1] 6\n\n\n\nTo access the help pages on R functions, just type help(function_name) or ?function_name.\n\n# Example: open the documentation about the function sum\nhelp (sum)    \n# Quick access to help page about sum\n?sum          \n\nRStudio auto-completes your commands by showing you possible alternatives as soon as you type 3 consecutive characters. If you want to see the options for less than 3 chars to get help on available functions, just press tab to display available options. Tip: Use auto-complete as much as possible to avoid typing mistakes.\nThere are 4 main vector data types in R: Logical (TRUE or FALSE); Numeric (e.g. 1,2,3…); Character (i.e. text, for example “u”, “alg”, “arve”) and Complex (e.g. 3+2i).\nVectors are ordered sets of elements. In R vectors are 1-based, i.e. the first index position is number 1 (as opposed to other programming languages whose indexes start at zero, like Python).\nR objects can be divided in two main groups: Functions and Data-related objects. Functions receive arguments inside circular brackets ( ) and objects receive arguments inside square brackets [ ]:\nfunction (arguments)\ndata.object [arguments]\nThere are five basic data structures in R: Vector, Matrix, Array, Data frame, and List (see following figure):\n\n\n12.1 The basic data structure in R is the vector, which requires all of its elements to be of the same type (e.g. all numeric; all character (text); all logical (TRUE or FALSE)).\n12.2 Matrices are two dimensional vectors (tables), where all columns are of the same length, and all from the same type.\n12.3 Data frames are the most flexible and commonly used R data structures, used to store datasets in spreadsheet-like tables. The columns can be vectors of different types (i.e. text, number, logical, etc, can all be stored in the same data frame), but each column must to be of the same data type.\n12.4 Lists are ordered sets of elements, that can be arbitrary R objects (vectors, data frames, matrices, strings, functions, other lists etc), and heterogeneous, i.e. each element can be of a different type and different lengths.\n\nR is column-major by default, meaning that the elements of a multi-dimensional array are linearly stored in memory column-wise. This is important for example when using data to populate a matrix.\n\n\nmatrix(1:9, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\nWhen subsetting matrices and data-frames, the first index is the row, and the second index is the column. If left empty (no value), then the full row or the full column is returned.\n\n\n# My letters matrix\n(my_letters &lt;- matrix(rep(LETTERS[1:3], each=3), ncol = 3))\n\n     [,1] [,2] [,3]\n[1,] \"A\"  \"B\"  \"C\" \n[2,] \"A\"  \"B\"  \"C\" \n[3,] \"A\"  \"B\"  \"C\" \n\n# Element in Row 1, Column 2\nmy_letters[1,2]\n\n[1] \"B\"\n\n# Element in Row 2, Column 3\nmy_letters[2,3]\n\n[1] \"C\"\n\n# Row 3\nmy_letters[3,]\n\n[1] \"A\" \"B\" \"C\"\n\n# Column 1\nmy_letters[,1]\n\n[1] \"A\" \"A\" \"A\"\n\n\n\n\n\nThe working directory is the location in the filesystem (folder) where R will look for input data and where it will save the output from your analysis. In RStudio you can graphically check this information.\ndir()   # list all files in your working directory\ngetwd() # find out the path to your working directory\nsetwd(\"/home/isabel\") # example of setting a new working directory path\n\n\n\nThe R environment is controlled by hidden files (files that start with a dot .) in the start-up directory: .RData, .Rhistory and .Rprofile (optional).\n\n.RData is a file containing all the objects, data, and functions created during a work-session. This file can then be loaded for future work without requiring the re-computation of the analysis. (Note: it can potentially be a very large file);\n\n.Rhistory saves all commands that have been typed during the R session;\n.Rprofile useful for advanced users to customize RStudio behavior.\n\nThese files can be renamed:\n# DO NOT RUN\nsave.image (file=\"myProjectName.RData\")\nsavehistory (file=\"myProjectName.Rhistory\")\n\nTo quit R just close RStudio, or use the q () function. You will then be asked if you want to save the workspace image (i.e. the .RData file):\nq()\nSave workspace image to ~/path/to/your/working/directory/.RData? [y/n/c]:\nIf you type y (yes), then the entire R workspace will be written to the .RData file (which can be very large). Often it is sufficient to just save an analysis script (i.e. a reproducible protocol) in an R source file. This way, one can quickly regenerate all data sets and objects for future analysis. The .RData file is particularly useful to save the results from analyses that require a long time to compute.\nIn RStudio, to quit your session, just hit the close button (x button), just like when you want to quit any other application in your computer.\nIn RStudio Server, you must log out of your account. When you log back in, your session will resume.\n\n\n\n\nIn R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. These packages are stored in online repositories from which they can be easily retrieved and installed on your computer (R packages by Hadley Wickham). There are 2 main R repositories:\n\nThe Comprehensive R Archive Network - CRAN (18927 packages in March 2022)\n\nBioconductor (2083 packages in March 2022) (bioscience data analysis)\n\nThis huge variety of packages is one of the reasons why R is so successful: the chances are that someone has already developed a method to solved the problem that you’re working on, and you can benefit from their work by downloading their package for free.\nIn this course, we will not use many packages. However, if you continue to use R for your data analyses you will need to install many more useful packages, particularly from Bioconductor — an open source, open development software project to provide tools for the analysis and comprehension of high-throughput genomics data […] based primarily on the R programming language.\n\n\n\n\nThere are several alternative ways to install packages in R. Depending on the repository from which you want to install a package, there are dedicated functions that facilitate this task:\n\ninstall.packages() built-in function to install packages from the CRAN repository;\nBiocManager::install() to install packages from the Bioconductor repository;\nremotes::install_github to install packages from GitHub (a code repository, not exclusively dedicated to R).\n\nAfter installing a package, you must load it to make its contents (functions and/or data) available. The loading is done with the function library(). Alternatively, you can prepend the name of the package followed by :: to the function name to use it (e.g. ggplot2::qplot()).\ninstall.packages(\"ggplot2\")   # install the package called ggplot2 from CRAN\nlibrary (\"ggplot2\")            # load the library ggplot2 \n\nhelp (package=ggplot2)         # help(package=\"package_name\") to get help about a specific package\nvignette (\"ggplot2\")           # show a pdf with the package manual (called R vignettes)\n\n\n\n\nRStudio Projects are a great functionality, easing the transition between dataset analyses, and allowing a fast navigation to your analysis/working directory. To create a new project:\nFile &gt; New Project... &gt; New Directory &gt; New Project\nDirectory name: compBiol_module1\nCreate project as a subdirectory of: ~/\n                           Browse... (directory/folder to save the class data)\nCreate Project\nProjects should be personalized by clicking on the menu in the right upper corner. The general options - R General - are the most important to customize, since they allow the definition of the RStudio “behavior” when the project is opened. The following suggestions are particularly useful:\nRestore .RData at startup - Yes (for analyses with +1GB of data, you should choose \"No\")\nSave .RData on exit - Ask\nAlways save history - Yes\n\n\n\nFigure 2: Customize Project"
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Technical requirements for the course | Mandatory:\n\nYou must bring your own laptop;\nYou must have administrator privileges to install software in your computer;\nThe following software and packages must be installed prior to the course:\n\nFirst install R: https://cran.r-project.org/;\nThen install RStudio: https://posit.co/download/rstudio-desktop/.\n\n\nR packages required:\n\n“tidyverse”, “patchwork”, “knitr”, “here”, “bioconductor”, “readxl”, “RColorBrewer” (basic packages)\n“edgeR”, “limma”, and “DESeq2” (for differential expression analysis)\n“gprofiler2” (for functional enrichment analysis)"
  },
  {
    "objectID": "4_tidy_data_visualization.html",
    "href": "4_tidy_data_visualization.html",
    "title": "Tidy data & Visualization with R",
    "section": "",
    "text": "Tidy data & Visualization with R"
  },
  {
    "objectID": "tutorial_day1.html",
    "href": "tutorial_day1.html",
    "title": "Day1",
    "section": "",
    "text": "How to import datasets into R.\n\nConduct descriptive statistics on the dataset to explore the data.\n\nBasic data visualization with histograms, boxplots, and scatterplots.\n\nHow to calculate the correlation between 2 (numerical) variables.\n\nHow to make a simple linear regression, and plot the line in the scatterplot.\n\nConduct a t-test for basic hypothesis testing.\n\nRecognize the differences between base R plotting and using the ggplots2 package.\n\n\n\n\nThe scientific experiment | Imagine that you are interested in determining the effects of a high-fat diet on gene expression. For this study, the scientists obtained data from 60 mice, where half were fed a lean-diet, and the other half a high-fat diet. All other living conditions were the same. Four weeks after, a biopsy of the mice’s liver was sequenced by RNA-seq, and all mice were weighted, and the sex and age were also recorded. The results from this analysis are saved in diet_mice_metadata.txt file, and the gene counts are in the file diet_mice_counts.xlsx.\n\n\n\nWhat is the research question? What is the hypothesis?\nHow many variables are in the study?\nWhich variable(s) are dependent? (Dependent or Response variables are the variables that we are interested in predicting or explaining.)\nWhich variable(s) are independent? (Independent or Explanatory variables are used to explain or predict the dependent variable.)\nWhich variable(s) are covariates? (Covariates are variables that are potentially related to the outcome of interest in a study, but are not the main variable under study - used to control for potential confounding factors in a study.)\nAre the “controls” appropriate? Why?"
  },
  {
    "objectID": "tutorial_day1.html#basic-data-analysis-lesson-1",
    "href": "tutorial_day1.html#basic-data-analysis-lesson-1",
    "title": "Day1",
    "section": "",
    "text": "How to import datasets into R.\n\nConduct descriptive statistics on the dataset to explore the data.\n\nBasic data visualization with histograms, boxplots, and scatterplots.\n\nHow to calculate the correlation between 2 (numerical) variables.\n\nHow to make a simple linear regression, and plot the line in the scatterplot.\n\nConduct a t-test for basic hypothesis testing.\n\nRecognize the differences between base R plotting and using the ggplots2 package.\n\n\n\n\nThe scientific experiment | Imagine that you are interested in determining the effects of a high-fat diet on gene expression. For this study, the scientists obtained data from 60 mice, where half were fed a lean-diet, and the other half a high-fat diet. All other living conditions were the same. Four weeks after, a biopsy of the mice’s liver was sequenced by RNA-seq, and all mice were weighted, and the sex and age were also recorded. The results from this analysis are saved in diet_mice_metadata.txt file, and the gene counts are in the file diet_mice_counts.xlsx.\n\n\n\nWhat is the research question? What is the hypothesis?\nHow many variables are in the study?\nWhich variable(s) are dependent? (Dependent or Response variables are the variables that we are interested in predicting or explaining.)\nWhich variable(s) are independent? (Independent or Explanatory variables are used to explain or predict the dependent variable.)\nWhich variable(s) are covariates? (Covariates are variables that are potentially related to the outcome of interest in a study, but are not the main variable under study - used to control for potential confounding factors in a study.)\nAre the “controls” appropriate? Why?"
  },
  {
    "objectID": "tutorial_day1.html#hands-on-exercises",
    "href": "tutorial_day1.html#hands-on-exercises",
    "title": "Day1",
    "section": "Hands-on exercises",
    "text": "Hands-on exercises\nWe will start by looking at the metadata file containing the variables related to each sample (i.e. each mouse): type of diet, final weight, gender, and age in months.\n\nA. Create a new project in RStudio\nStart by creating a new project in RStudio. Go to File &gt; New project, and follow the instructions.\nOnce you have are in the project folder, create a new R script file. Go to File &gt; New File &gt; R Script. A blank text file will appear above the console. Save it in your project folder with the name diet_analysis.R.\n\n\nB. Load the data and inspect it\n\nDownload the file diet_mice_metadata.txt (mice weights according to diet) from GitHub https://github.com/patterninstitute/rmind-workshop/blob/main/data/diet_mice_metadata.txt.\n\nSave the file in your current working directory where the RProject was created inside a folder named data.\n\nType the instructions inside grey boxes in pane number 2 of RStudio — the R Console. As you already know, the words after a # sign are comments not interpreted by R, so you do not need to copy them.\n\nIn the R console, you must hit enter after each command to obtain the result.\n\nIn the script file (R file), you must run the command by pressing the run button (on the top panel), or by selecting the code you want to run and pressing ctrl + enter.\n\n\nSave all your relevant/final commands (R instructions) to your script file to be available for later use.\n\n\n# Load required packages\nlibrary(tidyverse)     # to ease data wrangling and visualization\nlibrary(here)          # to help with file paths \nlibrary(RColorBrewer)  # color palettes\nlibrary(patchwork)     # combine plots in panels for figures\n\n# Load the file and save it to object mice_data\nmice_data &lt;- read.table(file=here(\"data/diet_mice_metadata.txt\"), \n                        header = TRUE,\n                        sep = \"\\t\", dec = \".\",\n                        stringsAsFactors = TRUE)\n\n\n\nC. Answer the following questions using R\n\n1. Briefly explore the dataset.\nWe should use descriptive statistics that summarize the sample data. We will use measures of central tendency — Mean, Median, and Mode —, and measures of dispersion (or variability) — Standard Deviation, Variance, Maximum, and Minimum.\n\n\n2. How is the variable “mouse weight” distributed?\nAfter summarizing the data, we should find appropriate plots to look at it. A first approach is to look at the frequency of the mouse weight values using a histogram.\n\n\n3. How is the variable “mouse weight” distributed in each diet?\nSince our data of interest is one categorical variable (type of diet), and one continuous variable (weight), a boxplot is one of the most informative.\n\n\n4. How are the other variables distributed?\nThere are other variables in our data for each mouse that could influence the results, namely gender (categorical variable) and age (discrete variable). We should also look at these data.\n\n\n5. What is the frequency of each variable?\n\n5.1 How many measurements do we have for each gender?\n5.2 How many measurements do we have for each diet?\n5.3 How many measurements do we have for each gender in each diet?\n5.4 What if we want to know the results for each of the three variables: age, diet, and gender?\n\n\n\n6. Is there a dependency between the age and the weight of the mice in our study?\n\n\n7. Is the correlation between the age and the weight of the mice different for males and females?\n\n\n8. Is the correlation between the age and the weight of the mice different for different diets?\n\n\n9. Does the type of diet influence the body weight of mice?\nCan we answer this question just by looking at the plot? Are these observations compatible with a scenario where the type of diet does not influence body weight?\n\n\n\n10. Now that we have calculated the T-test, shall we accept or reject the null hypothesis? What are the outputs in R from the t-test?\n\n\n\nFinal discussion\n\n\nTake some time to discuss the results with the other participants, and decide if H0 should be rejected or not, and how confident you are that your decision is reasonable. Can you propose solutions to improve your confidence on the results? Is the experimental design appropriate for the research question being asked? Is this experiment well controlled and balanced?"
  },
  {
    "objectID": "tutorial_day2.html",
    "href": "tutorial_day2.html",
    "title": "Day2",
    "section": "",
    "text": "1. Identify the main steps required for a RNA-seq data analysis\n2. Load the dataset\n3. Inspect the data"
  },
  {
    "objectID": "tutorial_day2.html#transcriptomics-data-analysis-lesson-2",
    "href": "tutorial_day2.html#transcriptomics-data-analysis-lesson-2",
    "title": "Day2",
    "section": "",
    "text": "1. Identify the main steps required for a RNA-seq data analysis\n2. Load the dataset\n3. Inspect the data"
  },
  {
    "objectID": "tutorial_day3.html",
    "href": "tutorial_day3.html",
    "title": "Day3",
    "section": "",
    "text": "1. Identify the R commands needed to run a complete differential expression analysis using edgeR and DESeq2.\n2. Visualize the results.\n3. Apply these commands to your data.\n\n\n\n\nLoad packages and data\n\n\n# Load required packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(edgeR)\nlibrary(limma)\nlibrary(DESeq2)\n\n# Create list to save the analysis objects\nde_edger &lt;- list()\nde_deseq &lt;- list()\n\n# Load gene counts data and sample metadata\ncounts &lt;- read_xlsx(here(\"data/diet_mice_counts.xlsx\"), col_names = TRUE, sheet = 1)\n\nmetadata &lt;- read.table(file=here(\"data/diet_mice_metadata.txt\"), \n                        header = TRUE,\n                        sep = \"\\t\", dec = \".\",\n                        stringsAsFactors = TRUE)\n\n\nCheck if the data and metadata sample ids match\n\n\n### Ensure the sample metadata matches the identity and order of the columns in the expression data\n\n# Order the sample ids from the metadata (smaller file) by the colnames from the counts\nif (setequal(colnames(counts)[-c(1, 2)], metadata$sample_id)) {\n  metadata &lt;- metadata[match(colnames(counts)[-c(1, 2)], metadata$sample_id),]\n} else {\n  stop(\"Error: The set of sample ids is not equal in both datasets.\")\n}\n\n\nRemove NAs, if present\n\n\n# Transform count data-frame to matrix with row names\n# and remove NAs (if they exist)\ncounts_matrix &lt;- counts[-1] %&gt;%\nna.omit() %&gt;%\ncolumn_to_rownames(var = \"gene_symbol\") %&gt;%\nas.matrix()\n\n\nedgeR analysis\n\nCreate design and contrast matrices | Modelling Diet and Gender\n\n# Design matrix using the model for categorical variables diet and gender\ndesign_diet &lt;- model.matrix( ~ 0 + diet + gender, data = metadata)\n#design_diet &lt;- model.matrix( ~ 0 + diet, data = metadata)\n\n# Contrasts matrix: Differences between diets\ncontrasts_diet &lt;- limma::makeContrasts(\n(dietfat - dietlean),\nlevels=colnames(design_diet)\n)\n\n\n# Create a list \n\n# Create a DGEList object\nde_edger$dge_data &lt;- DGEList(counts = counts_matrix)\n\n# Filter low-expression genes\nde_edger$keep &lt;- filterByExpr(de_edger$dge_data,\ndesign = design_diet)\n\nde_edger$dge_data_filtered &lt;- de_edger$dge_data[de_edger$keep, , \n                                                keep.lib.sizes=FALSE]\n\n# Perform Library Size Normalization | Slow step\nde_edger$dge_data_filtered &lt;- calcNormFactors(de_edger$dge_data_filtered)\n\n# Estimate dispersions | Slow step\nde_edger$dge_data_filtered &lt;- estimateDisp(de_edger$dge_data_filtered,\ndesign = design_diet)\n\n### To perform likelihood ratio tests\n# Fit the negative binomial generalized log-linear model\nde_edger$fit &lt;- glmFit(de_edger$dge_data_filtered,\ndesign=design_diet,\ncontrast = contrasts_diet)\n\n# Perform likelihood ratio tests\nde_edger$lrt &lt;- glmLRT(de_edger$fit)\n\n# Extract the differentially expressed genes\nde_edger$topGenes &lt;- topTags(de_edger$lrt, n=NULL,\nadjust.method = \"BH\", \nsort.by = \"PValue\", \np.value = 0.05)\n\n# Look at the Differentially expressed genes\nde_edger$topGenes\n\ndata frame with 0 columns and 0 rows\n\n\n\nDESeq2 analysis\n\nDetailed Explanations: https://hbctraining.github.io/DGE_workshop_salmon_online/lessons/04b_DGE_DESeq2_analysis.html\n\n# Step 1: Create a DESeqDataSet object\n# The matrix is generated by the function\nde_deseq$dds &lt;- DESeqDataSetFromMatrix(countData = counts_matrix,\n                              colData = metadata,\n                              design = ~ 0 + diet + gender)\n\n# Step 2: Run the DESeq function to perform the analysis\nde_deseq$dds &lt;- DESeq(de_deseq$dds)\n\n# Step 3: Extract results\n# Replace 'condition_treated_vs_untreated' with the actual comparison you are interested in\nde_deseq$results &lt;- results(de_deseq$dds, contrast = c(\"diet\", \"fat\", \"lean\"))\n\n# Step 4: Apply multiple testing correction\n# The results function by default applies the Benjamini-Hochberg procedure to control FDR\n# Extract results with adjusted p-value (padj) less than 0.05 (common threshold for significance)\nde_deseq$significant_results &lt;- de_deseq$results[which(de_deseq$results$padj &lt; 0.05), ]\n\n# View the differentially expressed genes\nde_deseq$significant_results[order(de_deseq$significant_results$padj), ]\n\nlog2 fold change (MLE): diet fat vs lean \nWald test p-value: diet fat vs lean \nDataFrame with 69 rows and 6 columns\n        baseMean log2FoldChange     lfcSE      stat      pvalue        padj\n       &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;\nACSF3    31.3372       -2.02757  0.409439  -4.95208 7.34246e-07 5.50685e-05\nACSM3    33.0905       -2.04259  0.434317  -4.70299 2.56379e-06 9.61422e-05\nACAD10   34.4381       -1.90459  0.444229  -4.28741 1.80769e-05 1.45713e-04\nTRIAP1   34.0932       -1.96599  0.450039  -4.36850 1.25104e-05 1.45713e-04\nECI1     27.5814       -1.81494  0.408689  -4.44087 8.95956e-06 1.45713e-04\n...          ...            ...       ...       ...         ...         ...\nPHYH     24.3400      -1.063285  0.430853  -2.46786   0.0135923   0.0156834\nACOT11   21.5426      -0.956752  0.393676  -2.43030   0.0150862   0.0171434\nTHEM4    21.9723      -0.958742  0.402069  -2.38452   0.0171014   0.0191433\nHINT2    22.3808      -0.959613  0.434832  -2.20686   0.0273238   0.0301365\nDECR1    29.0965      -1.013954  0.467673  -2.16808   0.0301523   0.0327743\n\n\n\n\n\n\n# DESeq2\n\n# DESeq2 creates a matrix when you use the counts() function\n## First convert normalized_counts to a data frame and transfer the row names to a new column called \"gene\"\nnormalized_counts &lt;- counts(de_deseq$dds, normalized=T) %&gt;% \n                     data.frame() %&gt;%\n                     rownames_to_column(var=\"gene_symbol\") %&gt;%\n                     as_tibble() \n\n# Plot expression for single gene\nplotCounts(de_deseq$dds, gene=\"TAMM41\", intgroup=\"diet\") \n\n\n\nplotCounts(de_deseq$dds, gene=\"TAMM41\", intgroup=\"gender\") \n\n\n\n# # Save plotcounts to a data frame object to use ggplots\nd &lt;- plotCounts(de_deseq$dds, gene=\"TAMM41\", intgroup=\"diet\", returnData=TRUE)\n\n# View d\nhead(d)\n\n          count diet\nmus48 20.373530  fat\nmus47 28.605416  fat\nmus54  0.500000  fat\nmus28  3.120844 lean\nmus52  8.149325  fat\nmus38  7.889512  fat\n\n# Draw with ggplot a single gene\nggplot(d, aes(x = diet, y = count, color = diet)) + \n    geom_point(position=position_jitter(w = 0.1,h = 0)) +\n    ggrepel::geom_text_repel(aes(label = rownames(d))) + \n    theme_bw() +\n    ggtitle(\"TAMM41\") +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n# View the top 20 genes\n## Order results by padj values\ntop12_sigOE_genes &lt;- rownames(as.data.frame(de_deseq$significant_results))[1:12]\n\n## normalized counts for top 20 significant genes\ntop12_sigOE_norm &lt;- normalized_counts %&gt;%\n        filter(gene_symbol %in% top12_sigOE_genes)\n\n# Make a tidy table to plot\ntop12_counts &lt;- pivot_longer(top12_sigOE_norm, starts_with(\"mus\"), names_to = \"sample_id\", values_to = \"ncounts\" )\n\n# Add metadata\ntop12_counts_metadata &lt;- left_join(top12_counts, metadata, by = \"sample_id\")\n\n# ## Plot using ggplot2\nggplot(top12_counts_metadata, aes(x = gene_symbol, y = ncounts)) +\n        geom_boxplot(aes(fill = diet)) +\n        scale_y_log10() +\n        xlab(\"Genes\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 12 Significant DE Genes\") +\n        theme_bw() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n# ## Boxplots of diet per genes\nggplot(top12_counts_metadata) +\n        geom_boxplot(aes(x = diet, y = ncounts, fill = diet)) +\n        scale_y_log10() +\n        xlab(\"Diet\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 12 Significant DE Genes\") +\n        theme_bw() +\n  facet_wrap(facets=\"gene_symbol\")\n\n\n\n# ## Boxplots of gender per genes\nggplot(top12_counts_metadata) +\n        geom_boxplot(aes(x = interaction(gender, diet), y = ncounts, \n                         fill = interaction(gender, diet)), show.legend = FALSE) +\n        scale_y_log10() +\n        xlab(\"Gender.Diet\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 12 Significant DE Genes\") +\n        theme_bw() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  facet_wrap(facets=\"gene_symbol\")\n\n\n\n## Volcanoplot \n\nas.data.frame(de_deseq$results) %&gt;%\n  rownames_to_column(var=\"gene_symbol\") -&gt; results_df\n\nggplot(results_df, aes(x=log2FoldChange, y=-log10(padj))) +\n  geom_point()\n\n\n\n\n\n\n\nDESeq2\n“DESeq: This normalization method is included in the DESeq Bioconductor package (version 1.6.0) and is based on the hypothesis that most genes are not DE. A DESeq scaling factor for a given lane is computed as the median of the ratio, for each gene, of its read count over its geometric mean across all lanes. The underlying idea is that non-DE genes should have similar read counts across samples, leading to a ratio of 1. Assuming most genes are not DE, the median of this ratio for the lane provides an estimate of the correction factor that should be applied to all read counts of this lane to fulfill the hypothesis. By calling the estimateSizeFactors() and sizeFactors() functions in the DESeq Bioconductor package, this factor is computed for each lane, and raw read counts are divided by the factor associated with their sequencing lane.”\nEdgeR\n“Trimmed Mean of M-values (TMM): This normalization method is implemented in the edgeR Bioconductor package (version 2.4.0). It is also based on the hypothesis that most genes are not DE. The TMM factor is computed for each lane, with one lane being considered as a reference sample and the others as test samples. For each test sample, TMM is computed as the weighted mean of log ratios between this test and the reference, after exclusion of the most expressed genes and the genes with the largest log ratios. According to the hypothesis of low DE, this TMM should be close to 1. If it is not, its value provides an estimate of the correction factor that must be applied to the library sizes (and not the raw counts) in order to fulfill the hypothesis. The calcNormFactors() function in the edgeR Bioconductor package provides these scaling factors. To obtain normalized read counts, these normalization factors are re-scaled by the mean of the normalized library sizes. Normalized read counts are obtained by dividing raw read counts by these re-scaled normalization factors.”\nhttps://www.ncbi.nlm.nih.gov/pubmed/22988256\n\n\n\nSelf-learning & Training | Differential Gene Expression Analysis (bulk RNA-seq)\nhttps://hbctraining.github.io/DGE_workshop_salmon_online/schedule/links-to-lessons.html"
  },
  {
    "objectID": "tutorial_day3.html#transcriptomics-data-analysis-lesson-3",
    "href": "tutorial_day3.html#transcriptomics-data-analysis-lesson-3",
    "title": "Day3",
    "section": "",
    "text": "1. Identify the R commands needed to run a complete differential expression analysis using edgeR and DESeq2.\n2. Visualize the results.\n3. Apply these commands to your data.\n\n\n\n\nLoad packages and data\n\n\n# Load required packages\nlibrary(here)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(edgeR)\nlibrary(limma)\nlibrary(DESeq2)\n\n# Create list to save the analysis objects\nde_edger &lt;- list()\nde_deseq &lt;- list()\n\n# Load gene counts data and sample metadata\ncounts &lt;- read_xlsx(here(\"data/diet_mice_counts.xlsx\"), col_names = TRUE, sheet = 1)\n\nmetadata &lt;- read.table(file=here(\"data/diet_mice_metadata.txt\"), \n                        header = TRUE,\n                        sep = \"\\t\", dec = \".\",\n                        stringsAsFactors = TRUE)\n\n\nCheck if the data and metadata sample ids match\n\n\n### Ensure the sample metadata matches the identity and order of the columns in the expression data\n\n# Order the sample ids from the metadata (smaller file) by the colnames from the counts\nif (setequal(colnames(counts)[-c(1, 2)], metadata$sample_id)) {\n  metadata &lt;- metadata[match(colnames(counts)[-c(1, 2)], metadata$sample_id),]\n} else {\n  stop(\"Error: The set of sample ids is not equal in both datasets.\")\n}\n\n\nRemove NAs, if present\n\n\n# Transform count data-frame to matrix with row names\n# and remove NAs (if they exist)\ncounts_matrix &lt;- counts[-1] %&gt;%\nna.omit() %&gt;%\ncolumn_to_rownames(var = \"gene_symbol\") %&gt;%\nas.matrix()\n\n\nedgeR analysis\n\nCreate design and contrast matrices | Modelling Diet and Gender\n\n# Design matrix using the model for categorical variables diet and gender\ndesign_diet &lt;- model.matrix( ~ 0 + diet + gender, data = metadata)\n#design_diet &lt;- model.matrix( ~ 0 + diet, data = metadata)\n\n# Contrasts matrix: Differences between diets\ncontrasts_diet &lt;- limma::makeContrasts(\n(dietfat - dietlean),\nlevels=colnames(design_diet)\n)\n\n\n# Create a list \n\n# Create a DGEList object\nde_edger$dge_data &lt;- DGEList(counts = counts_matrix)\n\n# Filter low-expression genes\nde_edger$keep &lt;- filterByExpr(de_edger$dge_data,\ndesign = design_diet)\n\nde_edger$dge_data_filtered &lt;- de_edger$dge_data[de_edger$keep, , \n                                                keep.lib.sizes=FALSE]\n\n# Perform Library Size Normalization | Slow step\nde_edger$dge_data_filtered &lt;- calcNormFactors(de_edger$dge_data_filtered)\n\n# Estimate dispersions | Slow step\nde_edger$dge_data_filtered &lt;- estimateDisp(de_edger$dge_data_filtered,\ndesign = design_diet)\n\n### To perform likelihood ratio tests\n# Fit the negative binomial generalized log-linear model\nde_edger$fit &lt;- glmFit(de_edger$dge_data_filtered,\ndesign=design_diet,\ncontrast = contrasts_diet)\n\n# Perform likelihood ratio tests\nde_edger$lrt &lt;- glmLRT(de_edger$fit)\n\n# Extract the differentially expressed genes\nde_edger$topGenes &lt;- topTags(de_edger$lrt, n=NULL,\nadjust.method = \"BH\", \nsort.by = \"PValue\", \np.value = 0.05)\n\n# Look at the Differentially expressed genes\nde_edger$topGenes\n\ndata frame with 0 columns and 0 rows\n\n\n\nDESeq2 analysis\n\nDetailed Explanations: https://hbctraining.github.io/DGE_workshop_salmon_online/lessons/04b_DGE_DESeq2_analysis.html\n\n# Step 1: Create a DESeqDataSet object\n# The matrix is generated by the function\nde_deseq$dds &lt;- DESeqDataSetFromMatrix(countData = counts_matrix,\n                              colData = metadata,\n                              design = ~ 0 + diet + gender)\n\n# Step 2: Run the DESeq function to perform the analysis\nde_deseq$dds &lt;- DESeq(de_deseq$dds)\n\n# Step 3: Extract results\n# Replace 'condition_treated_vs_untreated' with the actual comparison you are interested in\nde_deseq$results &lt;- results(de_deseq$dds, contrast = c(\"diet\", \"fat\", \"lean\"))\n\n# Step 4: Apply multiple testing correction\n# The results function by default applies the Benjamini-Hochberg procedure to control FDR\n# Extract results with adjusted p-value (padj) less than 0.05 (common threshold for significance)\nde_deseq$significant_results &lt;- de_deseq$results[which(de_deseq$results$padj &lt; 0.05), ]\n\n# View the differentially expressed genes\nde_deseq$significant_results[order(de_deseq$significant_results$padj), ]\n\nlog2 fold change (MLE): diet fat vs lean \nWald test p-value: diet fat vs lean \nDataFrame with 69 rows and 6 columns\n        baseMean log2FoldChange     lfcSE      stat      pvalue        padj\n       &lt;numeric&gt;      &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;\nACSF3    31.3372       -2.02757  0.409439  -4.95208 7.34246e-07 5.50685e-05\nACSM3    33.0905       -2.04259  0.434317  -4.70299 2.56379e-06 9.61422e-05\nACAD10   34.4381       -1.90459  0.444229  -4.28741 1.80769e-05 1.45713e-04\nTRIAP1   34.0932       -1.96599  0.450039  -4.36850 1.25104e-05 1.45713e-04\nECI1     27.5814       -1.81494  0.408689  -4.44087 8.95956e-06 1.45713e-04\n...          ...            ...       ...       ...         ...         ...\nPHYH     24.3400      -1.063285  0.430853  -2.46786   0.0135923   0.0156834\nACOT11   21.5426      -0.956752  0.393676  -2.43030   0.0150862   0.0171434\nTHEM4    21.9723      -0.958742  0.402069  -2.38452   0.0171014   0.0191433\nHINT2    22.3808      -0.959613  0.434832  -2.20686   0.0273238   0.0301365\nDECR1    29.0965      -1.013954  0.467673  -2.16808   0.0301523   0.0327743\n\n\n\n\n\n\n# DESeq2\n\n# DESeq2 creates a matrix when you use the counts() function\n## First convert normalized_counts to a data frame and transfer the row names to a new column called \"gene\"\nnormalized_counts &lt;- counts(de_deseq$dds, normalized=T) %&gt;% \n                     data.frame() %&gt;%\n                     rownames_to_column(var=\"gene_symbol\") %&gt;%\n                     as_tibble() \n\n# Plot expression for single gene\nplotCounts(de_deseq$dds, gene=\"TAMM41\", intgroup=\"diet\") \n\n\n\nplotCounts(de_deseq$dds, gene=\"TAMM41\", intgroup=\"gender\") \n\n\n\n# # Save plotcounts to a data frame object to use ggplots\nd &lt;- plotCounts(de_deseq$dds, gene=\"TAMM41\", intgroup=\"diet\", returnData=TRUE)\n\n# View d\nhead(d)\n\n          count diet\nmus48 20.373530  fat\nmus47 28.605416  fat\nmus54  0.500000  fat\nmus28  3.120844 lean\nmus52  8.149325  fat\nmus38  7.889512  fat\n\n# Draw with ggplot a single gene\nggplot(d, aes(x = diet, y = count, color = diet)) + \n    geom_point(position=position_jitter(w = 0.1,h = 0)) +\n    ggrepel::geom_text_repel(aes(label = rownames(d))) + \n    theme_bw() +\n    ggtitle(\"TAMM41\") +\n    theme(plot.title = element_text(hjust = 0.5))\n\n\n\n# View the top 20 genes\n## Order results by padj values\ntop12_sigOE_genes &lt;- rownames(as.data.frame(de_deseq$significant_results))[1:12]\n\n## normalized counts for top 20 significant genes\ntop12_sigOE_norm &lt;- normalized_counts %&gt;%\n        filter(gene_symbol %in% top12_sigOE_genes)\n\n# Make a tidy table to plot\ntop12_counts &lt;- pivot_longer(top12_sigOE_norm, starts_with(\"mus\"), names_to = \"sample_id\", values_to = \"ncounts\" )\n\n# Add metadata\ntop12_counts_metadata &lt;- left_join(top12_counts, metadata, by = \"sample_id\")\n\n# ## Plot using ggplot2\nggplot(top12_counts_metadata, aes(x = gene_symbol, y = ncounts)) +\n        geom_boxplot(aes(fill = diet)) +\n        scale_y_log10() +\n        xlab(\"Genes\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 12 Significant DE Genes\") +\n        theme_bw() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    theme(plot.title = element_text(hjust = 0.5)) \n\n\n\n# ## Boxplots of diet per genes\nggplot(top12_counts_metadata) +\n        geom_boxplot(aes(x = diet, y = ncounts, fill = diet)) +\n        scale_y_log10() +\n        xlab(\"Diet\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 12 Significant DE Genes\") +\n        theme_bw() +\n  facet_wrap(facets=\"gene_symbol\")\n\n\n\n# ## Boxplots of gender per genes\nggplot(top12_counts_metadata) +\n        geom_boxplot(aes(x = interaction(gender, diet), y = ncounts, \n                         fill = interaction(gender, diet)), show.legend = FALSE) +\n        scale_y_log10() +\n        xlab(\"Gender.Diet\") +\n        ylab(\"log10 Normalized Counts\") +\n        ggtitle(\"Top 12 Significant DE Genes\") +\n        theme_bw() +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  facet_wrap(facets=\"gene_symbol\")\n\n\n\n## Volcanoplot \n\nas.data.frame(de_deseq$results) %&gt;%\n  rownames_to_column(var=\"gene_symbol\") -&gt; results_df\n\nggplot(results_df, aes(x=log2FoldChange, y=-log10(padj))) +\n  geom_point()\n\n\n\n\n\n\n\nDESeq2\n“DESeq: This normalization method is included in the DESeq Bioconductor package (version 1.6.0) and is based on the hypothesis that most genes are not DE. A DESeq scaling factor for a given lane is computed as the median of the ratio, for each gene, of its read count over its geometric mean across all lanes. The underlying idea is that non-DE genes should have similar read counts across samples, leading to a ratio of 1. Assuming most genes are not DE, the median of this ratio for the lane provides an estimate of the correction factor that should be applied to all read counts of this lane to fulfill the hypothesis. By calling the estimateSizeFactors() and sizeFactors() functions in the DESeq Bioconductor package, this factor is computed for each lane, and raw read counts are divided by the factor associated with their sequencing lane.”\nEdgeR\n“Trimmed Mean of M-values (TMM): This normalization method is implemented in the edgeR Bioconductor package (version 2.4.0). It is also based on the hypothesis that most genes are not DE. The TMM factor is computed for each lane, with one lane being considered as a reference sample and the others as test samples. For each test sample, TMM is computed as the weighted mean of log ratios between this test and the reference, after exclusion of the most expressed genes and the genes with the largest log ratios. According to the hypothesis of low DE, this TMM should be close to 1. If it is not, its value provides an estimate of the correction factor that must be applied to the library sizes (and not the raw counts) in order to fulfill the hypothesis. The calcNormFactors() function in the edgeR Bioconductor package provides these scaling factors. To obtain normalized read counts, these normalization factors are re-scaled by the mean of the normalized library sizes. Normalized read counts are obtained by dividing raw read counts by these re-scaled normalization factors.”\nhttps://www.ncbi.nlm.nih.gov/pubmed/22988256\n\n\n\nSelf-learning & Training | Differential Gene Expression Analysis (bulk RNA-seq)\nhttps://hbctraining.github.io/DGE_workshop_salmon_online/schedule/links-to-lessons.html"
  },
  {
    "objectID": "5_ggplot_intro.html",
    "href": "5_ggplot_intro.html",
    "title": "ggplot2",
    "section": "",
    "text": "Any data analysis pipeline starts by tidying your data, which is the process of cleaning, transforming, and reorganizing data to make it suitable for analysis and visualization.\n\n\n\n\n\nggplot2 is a popular package for data visualization in R. It is based on the “grammar of graphics” framework, which emphasizes the modular construction of a plot using different layers and components (ggplot2 online documentation here).\nThe basic syntax of ggplot2 involves three main components:\n\nthe data,\n\nthe aesthetics (aes()),\n\nand the geometric objects (geom()).\n\n\n\n\n\nFrom: https://github.com/rfortherestofus/fundamentals\n\n\n\n\n\n\npatchwork is an R package that provides a simple way to combine multiple plots created with ggplot2 into a single panel or figure. It allows users to create complex and customized layouts of multiple plots, arranged in rows or columns, and adding labels or titles to the panel (patchwork online documentation here).\n\nThe plots are combined and their layout is defined using the following symbols:\n\n+ (combine the plots in a square grid shape, e.g. 2x2, or 3x3);\n\n| (place plots next to each other into equal sized grid portions);\n\n/ (place plots on top of each other).\n\n() (group the plots into a single portion of the grid).\n\nExample: plot1 | (plot2 / plot3)\n\n\n\n\nFrom: https://patchwork.data-imaginist.com/articles/patchwork.html\n\n\n\n\n\n\nThree key principles of effective data visualization are:\n\nClarity | A good data visualization should be easy to understand, with clear labels, axes, and legends that explain what the data represents.\nSimplicity | Visualizations should be simple, avoiding unnecessary clutter or visual noise that can distract from the main message. Remember: “Less is more.”\nHonesty | Data visualizations should accurately represent the data being presented, avoiding misleading or deceptive representations that can distort or misrepresent the data.\n\nIn addition to these key principles, it’s important to be aware of some common mistakes to avoid when creating data visualizations:\n\nDistorting the data | Visualizations should accurately represent the data being presented, without distorting or misrepresenting the underlying information.\nUsing inappropriate visual encoding | Choosing the wrong type of chart or visual encoding can lead to confusion or misinterpretation of the data.\nFailing to consider the audience | It’s important to consider who your audience is and what information they need to understand the data being presented.\n\nTo learn more about data visualization and ggplot2, here are some additional resources:\n\nStorytelling with Data by Cole Nussbaumer Knaflic\nR Graph Gallery\n\n\n\n\n\n\n\nhttps://www.rforecology.com/post/a-simple-introduction-to-ggplot2/\nhttps://rfortherestofus.github.io/fundamentals/slides/data-visualization-slides.html#4\n\nhttps://ouyanglab.com/covid19dataviz/ggplot2.html"
  },
  {
    "objectID": "5_ggplot_intro.html#fundamentals",
    "href": "5_ggplot_intro.html#fundamentals",
    "title": "ggplot2",
    "section": "",
    "text": "Any data analysis pipeline starts by tidying your data, which is the process of cleaning, transforming, and reorganizing data to make it suitable for analysis and visualization.\n\n\n\n\n\nggplot2 is a popular package for data visualization in R. It is based on the “grammar of graphics” framework, which emphasizes the modular construction of a plot using different layers and components (ggplot2 online documentation here).\nThe basic syntax of ggplot2 involves three main components:\n\nthe data,\n\nthe aesthetics (aes()),\n\nand the geometric objects (geom()).\n\n\n\n\n\nFrom: https://github.com/rfortherestofus/fundamentals\n\n\n\n\n\n\npatchwork is an R package that provides a simple way to combine multiple plots created with ggplot2 into a single panel or figure. It allows users to create complex and customized layouts of multiple plots, arranged in rows or columns, and adding labels or titles to the panel (patchwork online documentation here).\n\nThe plots are combined and their layout is defined using the following symbols:\n\n+ (combine the plots in a square grid shape, e.g. 2x2, or 3x3);\n\n| (place plots next to each other into equal sized grid portions);\n\n/ (place plots on top of each other).\n\n() (group the plots into a single portion of the grid).\n\nExample: plot1 | (plot2 / plot3)\n\n\n\n\nFrom: https://patchwork.data-imaginist.com/articles/patchwork.html\n\n\n\n\n\n\nThree key principles of effective data visualization are:\n\nClarity | A good data visualization should be easy to understand, with clear labels, axes, and legends that explain what the data represents.\nSimplicity | Visualizations should be simple, avoiding unnecessary clutter or visual noise that can distract from the main message. Remember: “Less is more.”\nHonesty | Data visualizations should accurately represent the data being presented, avoiding misleading or deceptive representations that can distort or misrepresent the data.\n\nIn addition to these key principles, it’s important to be aware of some common mistakes to avoid when creating data visualizations:\n\nDistorting the data | Visualizations should accurately represent the data being presented, without distorting or misrepresenting the underlying information.\nUsing inappropriate visual encoding | Choosing the wrong type of chart or visual encoding can lead to confusion or misinterpretation of the data.\nFailing to consider the audience | It’s important to consider who your audience is and what information they need to understand the data being presented.\n\nTo learn more about data visualization and ggplot2, here are some additional resources:\n\nStorytelling with Data by Cole Nussbaumer Knaflic\nR Graph Gallery\n\n\n\n\n\n\n\nhttps://www.rforecology.com/post/a-simple-introduction-to-ggplot2/\nhttps://rfortherestofus.github.io/fundamentals/slides/data-visualization-slides.html#4\n\nhttps://ouyanglab.com/covid19dataviz/ggplot2.html"
  },
  {
    "objectID": "3_self_eval_exam.html",
    "href": "3_self_eval_exam.html",
    "title": "R Self-evaluation",
    "section": "",
    "text": "These instructions will point you towards the self-evaluating exam, where you will be able to answer some basic data analysis questions using R. This is just for participants that already know some R, to check their knowledge and identify potential difficulties.\n\nFor this task, please install the ualg.compbio package (developed by Isabel Duarte and Ramiro Magno) from the instructr repository in GitHub:\n\n# Make sure you have the package `remotes` installed (to install packages from non-CRAN and non-Bioconductor repositories, such as GitHub):\ninstall.packages('remotes')\n\n# Make sure you have the package `learnr` required to run the self-eval exam\ninstall.packages('learnr')\n\n# Now you can install the ualg.compbio package from GitHub:\nremotes::install_github(\"instructr/ualg.compbio\")\n\nRun the self_eval_exam from the ualg.compbio package:\n\nlearnr::run_tutorial('self_eval_exam', package = 'ualg.compbio')\n\nPlease complete the exam (ideally you should not take longer than 30 minutes)."
  },
  {
    "objectID": "3_self_eval_exam.html#using-the-self-evaluation-exam",
    "href": "3_self_eval_exam.html#using-the-self-evaluation-exam",
    "title": "R Self-evaluation",
    "section": "",
    "text": "These instructions will point you towards the self-evaluating exam, where you will be able to answer some basic data analysis questions using R. This is just for participants that already know some R, to check their knowledge and identify potential difficulties.\n\nFor this task, please install the ualg.compbio package (developed by Isabel Duarte and Ramiro Magno) from the instructr repository in GitHub:\n\n# Make sure you have the package `remotes` installed (to install packages from non-CRAN and non-Bioconductor repositories, such as GitHub):\ninstall.packages('remotes')\n\n# Make sure you have the package `learnr` required to run the self-eval exam\ninstall.packages('learnr')\n\n# Now you can install the ualg.compbio package from GitHub:\nremotes::install_github(\"instructr/ualg.compbio\")\n\nRun the self_eval_exam from the ualg.compbio package:\n\nlearnr::run_tutorial('self_eval_exam', package = 'ualg.compbio')\n\nPlease complete the exam (ideally you should not take longer than 30 minutes)."
  },
  {
    "objectID": "introduction_day1.html",
    "href": "introduction_day1.html",
    "title": "Introduction",
    "section": "",
    "text": "Welcome\nWelcome to the Day 1 of the R-Mind workshop. We are very pleased to host this workshop for you.\n\nBriefly introduce yourself\n\nName\nPosition (Master’s student, PhD student, Postdoc, …)\nExpectations for this course\nSomething special about you so that we can remember you by!\n\n\n\n\nLet’s chat a bit about OMICs…\n\nWhat is “OMICs”?\nWhat is a genome?\nHow big is the human genome (in basepairs)?\n\nAround 3 billion bp (3Gbp)\n\nHow many genes are there in the human genome?\n\nGENCODE v44 | Total genes=62,700 | Protein-coding genes = 19,396\n\nHow about mouse genes?\n\nGENCODE M33 | Total genes=56,884 | Protein-coding genes = 21,403\n\nWhat is a transcriptome?\nWhat is High-throughput Sequencing (HTS) and Next-generation sequencing (NGS)?\nWhat are the most common HTS applications (i.e. types of sequencing)?\n\nExplore Sequencing Methods\n\nWhat is R, and why should I care?\n\n\n\nAdditional resources\nTraining courses: Bioinformatics Training at the Harvard Chan Bioinformatics Core\nBook: Modern Statistics for Modern Biology\n\n\nCheatSheets\nBase R\nggplot2\ndplyr\n\n\n\n\nReferences\nThis workshop is based on the training materials from the Harvard Chan Bioinformatics Core (HBC).\nMeeta Mistry, Mary Piper, Jihe Liu, & Radhika Khetani. (2021, May 24). hbctraining/DGE_workshop_salmon_online: Differential Gene Expression Workshop Lessons from HCBC (first release). Zenodo. https://doi.org/10.5281/zenodo.4783481"
  },
  {
    "objectID": "2_hands_on_tutorial.html",
    "href": "2_hands_on_tutorial.html",
    "title": "R4AB | Hands on tutorial",
    "section": "",
    "text": "This mini hands-on tutorial serves as an introduction to basic R, covering the following topics:\n\nOnline sources of information about R;\nPackages, Documentation and Help;\nBasics and syntax of R;\nMain R data structures: Vectors, Matrices, Data frames, Lists, and Factors;\nBrief intro to R control-flow via Loops and Conditionals;\nBrief description of function declaration;\nListing of some of the most commonly used built-in functions in R.\n\n\n\n\nThis protocol is divided into 7 parts, each one identified by a Title, Maximum execution time (in parenthesis), a brief Task description and the R commands to be executed. These will always be inside grey text boxes, with the font colored according to the R syntax highlighting.\n\n\n\n\n\nWebsites\n\nR Project (The developers of R)\nQuick-R (Roadmap and R code to quickly use R)\nCookbook for R (R code “recipes”)\nBioconductor workflows (R code for pipelines of genomic analyses)\nIntroduction to Data Science (Free online book from Rafael A. Irizarry, 2020)\nAdvanced R (If you want to learn R from a programmers perspective)\n\nBooks\n\nIntroductory Statistics with R (Springer, Dalgaard, 2008)\nA first course in statistical programming with R (CUP, Braun and Murdoch, 2016)\nComputational Genome Analysis: An Introduction (Springer, Deonier, Tavaré and Waterman, 2005)\nR programming for Bioinformatics (CRC Press, Gentleman, 2008)\nR for Data Science: Import, Tidy, Transform, Visualize, and Model Data (O’Reilly, Wickham and Grolemund, 2017) (for advanced users)\n\n\n\n\n\n\n\n\nR is case sensitive - be aware of capital letters (b is different from B).\nAll R code lines starting with the # (hash) sign are interpreted as comments, and therefore not evaluated.\n\n\n\n# This is a comment\n# 3 + 4   # this code is not evaluated, so and it does not print any result\n2 + 3     # the code before the hash sign is evaluated, so it prints the result (value 5)\n\n[1] 5\n\n\n\nExpressions in R are evaluated from the innermost parenthesis toward the outermost one (following proper mathematical rules).\n\n\n# Example with parenthesis:\n((2+2)/2)-2\n\n[1] 0\n\n# Without parenthesis:\n2+2/2-2\n\n[1] 1\n\n\n\nSpaces matter in variable names — use a dot or underscore to create longer names to make the variables more descriptive, e.g. my.variable_name.\n\nSpaces between variables and operators do not matter: 3+2 is the same as 3 + 2, and function (arg1 , arg2) is the same as function(arg1,arg2).\n\nIf you want to write 2 expressions/commands in the same line, you have to separate them by a ; (semi-colon)\n\n\n#Example:\n3 + 2 ; 5 + 1  \n\n[1] 5\n\n\n[1] 6\n\n\n\nMore recent versions of RStudio auto-complete your commands by showing you possible alternatives as soon as you type 3 consecutive characters, however, if you want to see the options for less than 3 chars, just press tab to display available options. Tip: Use auto-complete as much as possible to avoid typing mistakes.\nThere are 4 main vector data types: Logical (TRUE or FALSE); Numeric (e.g. 1,2,3…); Character (e.g. “u”, “alg”, “arve”) and Complex (e.g. 3+2i)\nVectors are ordered sets of elements. In R vectors are 1-based, i.e. the first index position is number 1 (as opposed to other programming languages whose indexes start at zero).\nR objects can be divided in two main groups: Functions and Data-related objects. Functions receive arguments inside circular brackets ( ) and objects receive arguments inside square brackets [ ]:\nfunction (arguments)\ndata.object [arguments]\n\n\n\n\n\nRStudio can be opened by double-clicking its icon.\nThe R environment is controlled by hidden files (files that start with a .) in the start-up directory: .RData, .Rhistory and .Rprofile (optional).\n\n.RData is a file containing all the objects, data, and functions created during a work-session. This file can then be loaded for future work without requiring the re-computation of the analysis. (Note: it can potentially be a very large file);\n.Rhistory saves all commands that have been typed during the R session;\n.Rprofile useful for advanced users to customize RStudio behavior.\n\nIt is always good practice to rename these files:\n# DO NOT RUN\nsave.image (file=\"myProjectName.RData\")\nsavehistory (file=\"myProjectName.Rhistory\")\n\nTo quit R, just close RStudio or use the q () function, and you will be asked if you want to save the workspace image (i.e. the .RData file):\nq()\nSave workspace image to ~/path/to/your/working/directory/.RData? [y/n/c]:\nBy typing y (yes), then the entire R workspace will be written to the .RData file (which can be very large). Often it is sufficient to just save an analysis script (i.e. a reproducible protocol) in an R source file. This way, one can quickly regenerate all data sets and objects for future analysis. The .RData file is particularly useful to save the results from analyses that require a long time to compute, and to keep checkpoints of your analysis pipeline.\n\n\n\n\nIn R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. These packages are stored online from which they can be easily retrieved and installed on your computer (R packages by Hadley Wickham). There are 2 main R repositories:\n\nThe Comprehensive R Archive Network - CRAN (14297 packages in May2019)\nBioconductor (1741 packages in May 2019) (bioscience data analysis)\n\nThis huge variety of packages is one of the reasons why R is so successful: the chances are that someone has already solved a problem that you’re working on, and you can benefit from their work by downloading their package for free.\n\n\n\n\nIn this tutorial you will not use any packages. However, if you continue to use R for biodata analysis you will surely need to install many useful packages, both from CRAN and from Bioconductor (R repositories), and from other code repositories such as GitHub.\n\n\nThere are several alternative ways to install packages in R. Depending on the repository from which you want to install a package, there are dedicated functions that facilitate this task:\n\ninstall.packages() built-in function to install packages from the CRAN repository;\nBiocManager::install() to install packages from the Bioconductor repository;\nremotes::install_github to install packages from GitHub (a code repository, not exclusively dedicated to R).\n\nAfter installing a package, you must load it to make its contents (functions and/or data) available. The loading is done with the function library(). Alternatively, you can prepend the name of the package followed by :: to the function name to use it (e.g. ggplot2::qplot()).\nFirst lets learn how to install packages from CRAN and from Bioconductor. To install packages from CRAN, R provides the install.packages() function, and any installed package, to be used, must be loaded via the library() function.\n# install the package called ggplot2\ninstall.packages (\"ggplot2\")   \n\n# load the library ggplot2\nlibrary (\"ggplot2\")     \nTo install packages from Bioconductor, you must first install Bioconductor:\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install()\nOnce installed, you can now download packages from Bioconductor using the BiocManager::install() function. The package AnnotationDbi is one of the most used in the context of genomics. Lets install it as an example of how to install packages from the Bioconductor repository:\n# Install the package\nBiocManager::install(\"AnnotationDbi\")\n\n# Load the package\nlibrary(\"AnnotationDbi\")\nNow the functions provided by the ggplot2 and the AnnotationDbi packages are available to be used in R.\nTo install packages from GitHub, the easiest way is to install the remotes package first, and then install the package of interest.\n# Make sure you have the {remotes} installed:\ninstall.packages('remotes')\n\n# Now you can install the ualg.compbio package from GitHub with:\nremotes::install_github(\"instructr/ualg.compbio\")\nNow you will have the tutorials provided by the ualg.compbio package.\n\n\n\n\nBut how to get information/help on how to use any function in R? There are many built-in ways in which R can provide help regarding its functions and packages:\n# help(package=\"package_name\") to get help about a specific package\nhelp (package=ggplot2) \n\n# show a pdf with the package manual (called R vignettes)\nvignette (\"ggplot2\")   \n\n# ?function to get quick info about the function of interest\n?qplot  \n\n\n\n\nYour working environment is the place where the variables, functions, and data that you create are stored. More advanced users can create more than one environment.\nls()    # list all objects in your environment\ndir()   # list all files in your working directory\ngetwd() # find out the path to your working directory\nsetwd(\"/home/foo/bar/DATA/\") # example of setting a new working directory path\n\n\n\n\n\n\n\n\nTo start we will open RStudio. This is an Integrated Development Environment - IDE - that includes syntax-highlighting text editor (1 in Figure1), an R console to execute code (2 in Figure1), as well as workspace and history management (3 in Figure1), and tools for plotting and exporting images, browsing the workspace, managing packages and viewing html/pdf files created within RStudio (4 in Figure1).\n\n\n\nFigure 1: RStudio Graphical User Interface (GUI)\n\n\nProjects are a great functionality, easing the transition between different dataset analyses, and allowing a fast navigation to your analysis/working directory. To create a new project:\nFile &gt; New Project... &gt; New Directory &gt; New Project\nDirectory name: r-absoluteBeginners\nCreate project as a subdirectory of: ~/\n                           Browse... (directory/folder to save the workshop data)\nCreate Project\nProjects should be personalized by clicking on the menu in the right upper corner. The general options - R General - are the most important to customize, since they allow the definition of the RStudio “behavior” when the project is opened. The following suggestions are particularly useful:\nRestore .RData at startup - Yes (for analyses with +1GB of data, you should choose \"No\")\nSave .RData on exit - Ask\nAlways save history - Yes\n\n\n\nFigure 2: Customize Project\n\n\n\n\n\n\nImportant NOTE: Please create a new R Script file to save all the code you use for today’s tutorial and save it in your current working directory. Name it: r4ab_day1.R\n\n\n\nValues are assigned to named variables with an &lt;- (arrow) or an = (equal) sign. In most cases they are interchangeable, however it is good practice to use the arrow since it is explicit about the direction of the assignment. If the equal sign is used, the assignment occurs from left to right.\nx &lt;- 7     # assign the number 7 to a variable named x\nx          # R will print the value associated with variable x\n\ny &lt;- 9     # assign the number 9 to the variable y\n\nz = 3      # assign the value 3 to the variable z\n\n42 -&gt; lue  # assign the value 42 to the variable named lue\n\nx -&gt;  xx   # assign the value of x (which is the number 7) to the variable named xx\nxx         # print the value of xx\n\nmy_variable = 5   # assign the number 5 to the variable named my_variable\n\n\n\n\nAllow the direct comparison between values, and its result is always a TRUE or FALSE value:\n\n\n\nSymbol\nDescription\n\n\n\n\n==\nexactly the same (equal)\n\n\n!=\ndifferent (not equal)\n\n\n&lt;\nsmaller than\n\n\n&gt;\ngreater than\n\n\n&lt;=\nsmaller or equal\n\n\n&gt;=\ngreater or equal\n\n\n\n1 == 1   # TRUE\n1 != 1   # FALSE\nx &gt; 3    # TRUE (x is 7)\ny &lt;= 9   # TRUE (y is 9)\nmy_variable &lt; z   # FALSE (z is 3 and my_variable is 5)\n\n\n\n\nCompare logical (TRUE or FALSE) values:\n\n\n\nSymbol\nDescription\n\n\n\n\n&\nAND (vectorized)\n\n\n&&\nAND (non-vectorized/evaluates only the first value)\n\n\n|\nOR (vectorized)\n\n\n||\nOR (non-vectorized/evaluates only the first value)\n\n\n!\nNOT\n\n\n\nQUESTION: Are these TRUE, or FALSE?\nx &lt; y & x &gt; 10   # AND means that both expressions have to be true to return TRUE\nx &lt; y | x &gt; 10   # OR means that only one expression must be true to return TRUE\n!(x != y & my_variable &lt;= y)  # yet another AND example using NOT\n\n\n\n\nR makes calculations using the following arithmetic operators:\n\n\n\nSymbol\nDescription\n\n\n\n\n+\nsummation\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n^\npower\n\n\n\n3 / y   ## 0.3333333\nx * 2   ## 14\n3 - 4   ## -1\n2^z     ## 8\nmy_variable + 2   ## 7\n\n\n\n\n\n\nR has 5 basic data structures (see following figure).\n\n\n\nFigure 3: Basic R data structures.\n\n\n\n\nThe basic data structure in R is the vector, which requires all of its elements to be of the same type (e.g. all numeric; all character (text); all logical (TRUE or FALSE)).\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nc\ncombine\n\n\n:\ninteger sequence\n\n\nseq\ngeneral sequence\n\n\nrep\nrepetitive patterns\n\n\n\nx &lt;- c (1,2,3,4,5,6)\nx\nclass (x)   # this function outputs the class of the object\n\ny &lt;- 10\nclass (y)\n\nz &lt;- \"a string\"\nclass (z)\n# The results are shown in the comments next to each line\n\nseq (1,6)   ## 1 2 3 4 5 6\nseq (from=100, by=1, length=5)   ## 100 101 102 103 104\n\n1:6    ## 1 2 3 4 5 6\n10:1   ## 10  9  8  7  6  5  4  3  2  1\n\nrep (1:2, 3)   ## 1 2 1 2 1 2\n\n\n\n\nMost arithmetic operations in the R language are vectorized, i.e. the operation is applied element-wise. When one operand is shorter than the other, the shortest one is recycled, i.e. the values from the shorter vector are re-used until the length of the longer vector is reached.\nPlease note that when one of the vectors is recycled, a warning is printed in the R Console. This warning is not an error, i.e. the operation has been completed despite the warning message.\n1:3 + 10:12\n\n# Notice the warning: this is recycling (the shorter vector \"restarts\" the \"cycling\")\n1:5 + 10:12\n\nx + y         # Remember that x = c(1,2,3,4,5,6) and y = 10\nc(70,80) + x\n\n\n\n\nSubsetting is one of the most powerful features of R. It is the extraction of one or more elements, which are of interest, from vectors, allowing for example the filtering of data, the re-ordering of tables, removal of unwanted data-points, etc. There are several ways of sub-setting data.\nNote: Please remember that indices in R are 1-based (see introduction).\n# Subsetting by indices\nmyVec &lt;- 1:26 ; myVec\nmyVec [1]    # prints the first value of myVec\nmyVec [6:9]  # prints the 6th, 7th, 8th, and 9th values of myVec \n\n# LETTERS is a built-in vector with the 26 letters of the alphabet\nmyLOL &lt;- LETTERS       # assign the 26 letters to the vector named myLOL\nmyLOL[c(3,3,13,1,18)]  # print the requested positions of vector myLOL\n\n#Subsetting by same length logical vectors\nmyLogical &lt;- myVec &gt; 10 ; myLogical\n# returns only the values in positions corresponding to TRUE in the logical vector\nmyVec [myLogical]\n\n\n\n\nReferring to an index by name rather than by position can make code more readable and flexible. Use the function names to attribute names to each position of the vector.\njoe &lt;- c (24, 1.70)\nnames (joe)              ## NULL\nnames (joe) &lt;- c (\"age\",\"height\")\nnames (joe)              ## \"age\"    \"height\"\njoe [\"age\"] == joe [1]   ## age   TRUE\n\nnames (myVec) &lt;- LETTERS\nmyVec\n# Subsetting by field names\nmyVec [c(\"A\", \"A\", \"B\", \"C\", \"E\", \"H\", \"M\")] ## The Fibonacci Series :o)\n\n\n\n\nSometimes we want to retain most elements of a vector, except for one or a few unwanted positions. Instead of specifying all elements of interest, it is easier to specify the ones we want to remove. This is easily done using the minus sign.\nalphabet &lt;- LETTERS\nalphabet   # print vector alphabet\nvowel.positions &lt;- c(1,5,9,15,21)\nalphabet[vowel.positions]    # print alphabet in vowel.positions\n\nconsonants &lt;- alphabet [-vowel.positions]  # exclude all vowels from the alphabet\nconsonants\n\n\n\n\nMatrices are two dimensional vectors (tables), where all columns are of the same length, and, just like one-dimensional vectors, matrices store same-type elements (e.g. all numeric; all character (text); all logical (TRUE or FALSE)). Matrices are explicitly created with the matrix function.\nIMPORTANT NOTE: R uses a column-major order for the internal linear storage of array values, meaning that first all of column 1 is stored, then all of column 2, etc. This implies that, by default, when you create a matrix, R will populate the first column, then the second, then the third, and so on until all values given to the matrix function are used. This is the default behavior of the matrix function, which can be changed via the byrow parameter (default value is set to FALSE).\nmy.matrix &lt;- matrix (1:12, nrow=3, byrow = FALSE)   # byrow = FALSE is the default (see ?matrix) \ndim (my.matrix)   # check the dimension (size) of the matrix: number of rows (first number) and number of columns (second number)\nmy.matrix         # print the matrix\n\nxx &lt;- matrix (1:12, nrow=3, byrow = TRUE)\ndim (xx)  # check if the dimensions of xx are the same as the dimensions of my.matrix\nxx        # compare my.matrix with xx and make sure you understand what is hapenning\n\n\n\n\nVery Important Note: The arguments inside the square brackets in matrices (and data.frames - see next section) are the [row_number, column_number]. If any of these is omitted, R assumes that all values are to be used: all rows, if the first value before the comma is missing; or all columns if the second value after the comma is missing.\n# Creating a matrix of characters\nmy.matrix &lt;- matrix (LETTERS, nrow = 4, byrow = TRUE) \n# Please notice the warning message (related to the \"recycling\" of the LETTERS)\n\nmy.matrix         # print the matrix\ndim (my.matrix)   # check the dimensions of the matrix\n\n# Subsetting by indices \nmy.matrix [,2]   # all rows, column 2 (returns a vector)\nmy.matrix [3,]   # row 3, all columns (returns a vector)\nmy.matrix [1:3,c(4,2)]   # rows 1, 2 and 3 from columns 4 and 2 (by this order) (returns a matrix)\n\n\n\n\nData frames are the most flexible and commonly used R data structures, used to store datasets in spreadsheet-like tables.\nIn a data.frame, usually the observations are the rows and the variables are the columns. Unlike matrices, the columns of a data frame can be vectors of different types (i.e. text, number, logical, etc, can all be stored in the same data frame). However, each column must to be of the same data type.\ndf &lt;- data.frame (type=rep(c(\"case\",\"control\"),c(2,3)),time=rnorm(5))  \n# rnorm is a random number generator retrieved from a normal distribution\n\nclass (df)   ## \"data.frame\"\ndf\n\n\n\n\nData frames are easily subset by index number using the square brackets notation [], or by column name using the dollar sign $.\nRemember: The arguments inside the square brackets, just like in matrices, are the [row_number, column_number]. If any of these is omitted, R assumes that all values are to be used.\nNOTE: R includes a package in its default base installation, named “The R Datasets Package”. This resource includes a diverse group of datasets, containing data from different fields: biology, physics, chemistry, economics, psychology, mathematics. These data are very useful to learn R. For more info about these datasets, run the following command: library(help=datasets)\nHere we will use the classic iris dataset to explore data frames, and learn how to subset them.\n# Familiarize yourself with the iris dataset (built-in dataset with measurements of iris flowers)\niris\n\n# Subset by indices the iris dataset\niris [,3]   # all rows, column 3 \niris [1,]   # row 1, all columns\niris [1:9, c(3,4,1,2)]   # rows 1 to 9 with columns 3, 4, 1 and 2 (in this order)\n\n# Subset by column name (for data.frames)\niris$Species            #show only the species column\niris[,\"Sepal.Length\"]\n\n# Select the time column from the df data frame created above\ndf$time      ## 0.5229577 0.7732990 2.1108504 0.4792064 1.3923535\n\n\n\n\nLists are very powerful data structures, consisting of ordered sets of elements, that can be arbitrary R objects (vectors, strings, functions, etc), and heterogeneous, i.e. each element of a different type.\nlst = list (a=1:3, b=\"hello\", fn=sqrt)   # index 3 contains the function \"square root\"\nlst\nlst$fn(49)   # outputs the square root of 49\n\n\n\n\nLike data frames they can be subset both by index number (inside square brackets) or by name using the dollar sign.\nNOTE: There is one subsetting feature that is particular to lists, which is the possibility of indexing using single square brackets [ ], or double square-brackets [[ ]]. The difference between these are the fact that, single brackets always return a list, while double brackets return the object in its native type (the same occurs with the dollar sign). For example, if the 3rd element of my.list is a data frame, then indexing the list using my.list[3] will return a list, of size 1 storing a data frame; but indexing it using my.list[[3]] will return the data frame itself.\n# Subsetting by indices\nlst [1]     # returns a list with the data contained in position 1 (preserves the type of data as list)\nclass (lst[1])\n\nlst [[1]]   # returns the data contained in position 1 (simplifies to inner data type) \nclass(lst[[1]])\n\n# Subsetting by name\nlst$b       # returns the data contained in position 1 (simplifies to inner data type)\nclass(lst$b)\n\n# Compare the class of these alternative indexing by name\nlst[\"a\"]\nlst[[\"a\"]]\n\n\n\n\nFactors are variables in R which take on a limited number of different values - such variables are often refered to as categorical variables.\n\n\n“One of the most important uses of factors is in statistical modeling; since categorical variables enter into statistical models differently than continuous variables, storing data as factors insures that the modeling functions will treat such data correctly.\nFactors in R are stored as a vector of integer values with a corresponding set of character values to use when the factor is displayed. The factor function is used to create a factor. The only required argument to factor is a vector of values which will be returned as a vector of factor values. Both numeric and character variables can be made into factors, but a factor’s levels will always be character values. You can see the possible levels for a factor through the levels command.\nFactors represent a very efficient way to store character values, because each unique character value is stored only once, and the data itself is stored as a vector of integers. Because of this, read.table will automatically convert character variables to factors unless the stringsAsFactors = FALSE argument is specified.”\n(Adapted from: https://www.stat.berkeley.edu/~s133/factors.html)\n# Create a vector of numbers to be displayed as Roman Numerals\nmy.fdata &lt;- c(1,2,2,3,1,2,3,3,1,2,3,3,1)\n# look at the vector\nmy.fdata\n\n# turn the data into factors\nfactor.data &lt;- factor(my.fdata)\n# look at the factors\nfactor.data\n\n# add labels to the levels of the data\nlabeled.data &lt;- factor(my.fdata,labels=c(\"I\",\"II\",\"III\"))\n# look at the factors\nlabeled.data\n# look only at the levels (i.e. character labels) of the factors\nlevels(labeled.data)\n\n\n\nData structures can be inter-converted (coerced) from one type to another. Sometimes it is useful to convert between data structure types (particularly when using packages).\nNOTE: Such conversions are not always possible without information loss - for example converting a data frame with mix data types to a matrix is not possible without converting all columns to the same type, possibly leading to losses.\nR has several functions for data structure conversions:\n# To check the class of the object:\nclass(lst)\n\n# To check the basic structure of an object:\nstr(lst)\n\n# \"Force\" the object to be of a certain type:\n # (this is not valid code, just a syntax example)\nas.matrix (myDataFrame)  # convert a data frame into a matrix\nas.numeric (myChar)      # convert text characters into numbers\nas.data.frame (myMatrix) # convert a matrix into a data frame\nas.character (myNumeric) # convert numbers into text chars\n\n\n\n\n\n\n\nR allows the implementation of loops, i.e. replicating instructions in an iterative way (also called cycles). The most common ones are for () loops and while () loops. The syntax for these loops is: for (condition) { code-block } and while (condition) { code-block }.\n# creating a for loop to calculate the first 12 values of the Fibonacci sequence\nmy.x &lt;- c(1,1)\nfor (i in 1:10) {\n  my.x &lt;- c(my.x, my.x[i] + my.x[i+1])\n  print(my.x)\n}\n\n# while loops will execute a block of commands until a condition is no longer satisfied\nx &lt;- 3 ; x\nwhile (x &lt; 9)\n{\n  cat(\"Number\", x, \"is smaller than 9.\\n\") # cat is a printing function (see ?cat)\n   x &lt;- x+1\n}\n\n\n\n\nConditionals allow running commands only when certain conditions are TRUE. The syntax is: if (condition) { code-block }.\nx &lt;- -5 ; x\nif (x &gt;= 0) { print(\"Non-negative number\") } else { print(\"Negative number\") }\n # Note: The else clause is optional. If the command is run at the command-line,\n  # and there is an else clause, then either all the expressions must be enclosed\n  # in curly braces, or the else statement must be in line with the if clause.\n\n# coupled with a for loop\nx &lt;- c(-5:5) ; x\nfor (i in 1:length(x)) {\n  if (x[i] &gt; 0) {\n     print(x[i])\n  } \n  else {\n   print (\"negative number\")\n  }\n}  \n\n\n\n\nThe ifelse function combines element-wise operations (vectorized) and filtering with a condition that is evaluated. The major advantage of the ifelse over the standard if-then-else statement is that it is vectorized. The syntax is: ifelse (condition-to-test, value-for-true, value-for-false).\n# re-code gender 1 as F (female) and 2 as M (male)\ngender &lt;- c(1,1,1,2,2,1,2,1,2,1,1,1,2,2,2,2,2)\nifelse(gender == 1, \"F\", \"M\")\n\n\n\n\n\nR allows defining new functions using the function command. The syntax (in pseudo-code) is the following:\nmy.function.name &lt;- function (argument1, argument2, ...) { \n  expression1\n  expression2\n  ...\n  return (value)\n  }\nNow, lets code our own function to calculate the average (or mean) of the values from a vector:\n# Define the function\n    # Please note that the function must be declared in the script before it can be used\nmy.average &lt;- function (x) {\n  average.result &lt;- sum(x)/length(x)\n  return (average.result)\n}\n\n# Create the data vector\nmy.data &lt;- c(10,20,30)\n\n# Run the function using the vector as argument\nmy.average(my.data)\n\n# Compare with R built-in mean function\nmean(my.data)\n\n\n\n\nMost R users need to load their own datasets, usually saved as table files (e.g. Excel, or .csv files), to be able to analyse and manipulate them. After the analysis, the results need to be exported/saved (e.g. to view or use with other software).\n# Inspect the esoph built-in dataset\nesoph\ndim(esoph)\ncolnames(esoph)\n\n### Saving ###\n# Save to a file named esophData.csv the esoph R dataset, separated by commas and\n # without quotes (the file will be saved in the current working directory)\nwrite.table (esoph, file=\"esophData.csv\", sep=\",\" , quote=F)\n\n# Save to a file named esophData.tab the esoph dataset, separated by tabs and without\n # quotes (the file will be saved in the current working directory)\nwrite.table (esoph, file=\"esophData.tab\", sep=\"\\t\" , quote=F)\n\n### Loading ###\n# Load a data file into R (the file should be in the working directory)\n  # read a table with columns separated by tabs\nmy.data.tab &lt;- read.table (\"esophData.tab\", sep=\"\\t\", header=TRUE)\n # read a table with columns separated by commas\nmy.data.csv &lt;- read.csv (\"esophData.csv\", header=T)\nNote: if you want to load or save the files in directories different from the working directory, just use (inside quotes) the full path as the first argument, instead of just the file name (e.g. “/home/Desktop/r_Workshop/esophData.csv”).\n\n\n\n\n\n\n# the unique function returns a vector with unique entries only (remove duplicated elements)\nunique (iris$Sepal.Length)\n\n# length returns the size of the vector (i.e. the number of elements)\nlength (unique (iris$Sepal.Length))\n\n# table counts the occurrences of entries (tally)\ntable (iris$Species)\n\n# aggregate computes statistics of data aggregates (groups)\naggregate (iris[,1:4], by=list (iris$Species), FUN=mean, na.rm=T)\n\n# the %in% function returns the intersection between two vectors\nmonth.name [month.name %in% c(\"CCMar\",\"May\", \"Fish\", \"July\", \"September\",\"Cool\")]\n\n# merge joins data frames based on a common column (that functions as a \"key\")\ndf1 &lt;- data.frame(x=1:5, y=LETTERS[1:5]) ; df1\ndf2 &lt;- data.frame(x=c(\"Eu\",\"Tu\",\"Ele\"), y=1:6) ; df2\nmerge (df1, df2, by.x=1, by.y=2, all = TRUE)\n\n# cbind and rbind (takes a sequence of vector, matrix or data-frame arguments\n # and combine them by columns or rows, respectively)\nmy.binding &lt;- as.data.frame(cbind(1:7, LETTERS[1:7]))    # the '1' (shorter vector) is recycled\nmy.binding\nmy.binding &lt;- cbind(my.binding, 8:14)[, c(1, 3, 2)] # insert a new column and re-order them\nmy.binding\n\nmy.binding2 &lt;- rbind(seq(1,21,by=2), c(1:11))\nmy.binding2\n\n# reverse the vector\nrev (LETTERS)\n# sum and cumulative sum\nsum (1:50); cumsum (1:50)\n# product and cumulative product\nprod (1:25); cumprod (1:25)\n\n### Playing with some R built-in datasets (see library(help=datasets) )\niris   # familiarize yourself with the iris data\n\n# mean, standard deviation, variance and median \nmean (iris[,2]); sd (iris[,2]); var (iris[,2]); median (iris[,2]) \n\n# minimum, maximum, range and summary statistics\nmin (iris[,1]); max (iris[,1]); range (iris[,1]); summary (iris)\n\n# exponential, logarithm\nexp (iris[1,1:4]); log (iris[1,1:4])\n\n# sine, cosine and tangent (radians, not degrees)\nsin (iris[1,1:4]); cos (iris[1,1:4]); tan (iris[1,1:4]) \n\n# sort, order and rank the vector\nsort (iris[1,1:4]); order (iris[1,1:4]); rank (iris[1,1:4])\n\n# useful to be used with if conditionals\nany (iris[1,1:4] &gt; 2)   # ask R if there are any values higher that 2? \nall (iris[1,1:4] &gt; 2)   # ask R if all values are higher than 2\n\n# select data\nwhich (iris[1,1:4] &gt; 2)\nwhich.max (iris[1,1:4]) \n\n# subset data by values/patterns from different columns \nsubset(iris, Petal.Length &gt;= 3 & Sepal.Length &gt;= 6.5, select=c(Petal.Length, Sepal.Length, Species))\n\n\n\n\nThe esoph (Smoking, Alcohol and (O)esophageal Cancer data) built-in dataset presents 2 types of variables: continuous numerical variables (the number of cases and the number of controls), and discrete categorical variables (the age group, the tobacco smoking group and the alcohol drinking group). Sometimes it is hard to “categorize” continuous variables, i.e. to group them in specific intervals of interest, and name these groups (also called levels).\nAccordingly, imagine that we are interested in classifying the number of cancer cases according to their occurrence: frequent, intermediate and rare. This type of variable re-coding into factors is easily accomplished using the function cut(), which divides the range of x into intervals and codes the values in x according to which interval they fall.\n# subset non-contiguous data from the esoph dataset\nesoph\nsummary(esoph)\n# cancers in patients consuming more than 30 g/day of tobacco\nsubset(esoph$ncases, esoph$tobgp == \"30+\")\n# total nr of cancers in patients older than 75\nsum(subset(esoph$ncases, esoph$agegp == \"75+\"))\n\n# factorize the nr of cases in 3 levels, equally spaced,\n # and add the new column named cat_ncases, to the dataset\nesoph$cat_ncases &lt;- cut (esoph$ncases,3,labels=c(\"rare\",\"med\",\"freq\"))\nsummary(esoph)\nThe end"
  },
  {
    "objectID": "2_hands_on_tutorial.html#hands-on-tutorial",
    "href": "2_hands_on_tutorial.html#hands-on-tutorial",
    "title": "R4AB | Hands on tutorial",
    "section": "",
    "text": "This mini hands-on tutorial serves as an introduction to basic R, covering the following topics:\n\nOnline sources of information about R;\nPackages, Documentation and Help;\nBasics and syntax of R;\nMain R data structures: Vectors, Matrices, Data frames, Lists, and Factors;\nBrief intro to R control-flow via Loops and Conditionals;\nBrief description of function declaration;\nListing of some of the most commonly used built-in functions in R.\n\n\n\n\nThis protocol is divided into 7 parts, each one identified by a Title, Maximum execution time (in parenthesis), a brief Task description and the R commands to be executed. These will always be inside grey text boxes, with the font colored according to the R syntax highlighting.\n\n\n\n\n\nWebsites\n\nR Project (The developers of R)\nQuick-R (Roadmap and R code to quickly use R)\nCookbook for R (R code “recipes”)\nBioconductor workflows (R code for pipelines of genomic analyses)\nIntroduction to Data Science (Free online book from Rafael A. Irizarry, 2020)\nAdvanced R (If you want to learn R from a programmers perspective)\n\nBooks\n\nIntroductory Statistics with R (Springer, Dalgaard, 2008)\nA first course in statistical programming with R (CUP, Braun and Murdoch, 2016)\nComputational Genome Analysis: An Introduction (Springer, Deonier, Tavaré and Waterman, 2005)\nR programming for Bioinformatics (CRC Press, Gentleman, 2008)\nR for Data Science: Import, Tidy, Transform, Visualize, and Model Data (O’Reilly, Wickham and Grolemund, 2017) (for advanced users)\n\n\n\n\n\n\n\n\nR is case sensitive - be aware of capital letters (b is different from B).\nAll R code lines starting with the # (hash) sign are interpreted as comments, and therefore not evaluated.\n\n\n\n# This is a comment\n# 3 + 4   # this code is not evaluated, so and it does not print any result\n2 + 3     # the code before the hash sign is evaluated, so it prints the result (value 5)\n\n[1] 5\n\n\n\nExpressions in R are evaluated from the innermost parenthesis toward the outermost one (following proper mathematical rules).\n\n\n# Example with parenthesis:\n((2+2)/2)-2\n\n[1] 0\n\n# Without parenthesis:\n2+2/2-2\n\n[1] 1\n\n\n\nSpaces matter in variable names — use a dot or underscore to create longer names to make the variables more descriptive, e.g. my.variable_name.\n\nSpaces between variables and operators do not matter: 3+2 is the same as 3 + 2, and function (arg1 , arg2) is the same as function(arg1,arg2).\n\nIf you want to write 2 expressions/commands in the same line, you have to separate them by a ; (semi-colon)\n\n\n#Example:\n3 + 2 ; 5 + 1  \n\n[1] 5\n\n\n[1] 6\n\n\n\nMore recent versions of RStudio auto-complete your commands by showing you possible alternatives as soon as you type 3 consecutive characters, however, if you want to see the options for less than 3 chars, just press tab to display available options. Tip: Use auto-complete as much as possible to avoid typing mistakes.\nThere are 4 main vector data types: Logical (TRUE or FALSE); Numeric (e.g. 1,2,3…); Character (e.g. “u”, “alg”, “arve”) and Complex (e.g. 3+2i)\nVectors are ordered sets of elements. In R vectors are 1-based, i.e. the first index position is number 1 (as opposed to other programming languages whose indexes start at zero).\nR objects can be divided in two main groups: Functions and Data-related objects. Functions receive arguments inside circular brackets ( ) and objects receive arguments inside square brackets [ ]:\nfunction (arguments)\ndata.object [arguments]\n\n\n\n\n\nRStudio can be opened by double-clicking its icon.\nThe R environment is controlled by hidden files (files that start with a .) in the start-up directory: .RData, .Rhistory and .Rprofile (optional).\n\n.RData is a file containing all the objects, data, and functions created during a work-session. This file can then be loaded for future work without requiring the re-computation of the analysis. (Note: it can potentially be a very large file);\n.Rhistory saves all commands that have been typed during the R session;\n.Rprofile useful for advanced users to customize RStudio behavior.\n\nIt is always good practice to rename these files:\n# DO NOT RUN\nsave.image (file=\"myProjectName.RData\")\nsavehistory (file=\"myProjectName.Rhistory\")\n\nTo quit R, just close RStudio or use the q () function, and you will be asked if you want to save the workspace image (i.e. the .RData file):\nq()\nSave workspace image to ~/path/to/your/working/directory/.RData? [y/n/c]:\nBy typing y (yes), then the entire R workspace will be written to the .RData file (which can be very large). Often it is sufficient to just save an analysis script (i.e. a reproducible protocol) in an R source file. This way, one can quickly regenerate all data sets and objects for future analysis. The .RData file is particularly useful to save the results from analyses that require a long time to compute, and to keep checkpoints of your analysis pipeline.\n\n\n\n\nIn R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. These packages are stored online from which they can be easily retrieved and installed on your computer (R packages by Hadley Wickham). There are 2 main R repositories:\n\nThe Comprehensive R Archive Network - CRAN (14297 packages in May2019)\nBioconductor (1741 packages in May 2019) (bioscience data analysis)\n\nThis huge variety of packages is one of the reasons why R is so successful: the chances are that someone has already solved a problem that you’re working on, and you can benefit from their work by downloading their package for free.\n\n\n\n\nIn this tutorial you will not use any packages. However, if you continue to use R for biodata analysis you will surely need to install many useful packages, both from CRAN and from Bioconductor (R repositories), and from other code repositories such as GitHub.\n\n\nThere are several alternative ways to install packages in R. Depending on the repository from which you want to install a package, there are dedicated functions that facilitate this task:\n\ninstall.packages() built-in function to install packages from the CRAN repository;\nBiocManager::install() to install packages from the Bioconductor repository;\nremotes::install_github to install packages from GitHub (a code repository, not exclusively dedicated to R).\n\nAfter installing a package, you must load it to make its contents (functions and/or data) available. The loading is done with the function library(). Alternatively, you can prepend the name of the package followed by :: to the function name to use it (e.g. ggplot2::qplot()).\nFirst lets learn how to install packages from CRAN and from Bioconductor. To install packages from CRAN, R provides the install.packages() function, and any installed package, to be used, must be loaded via the library() function.\n# install the package called ggplot2\ninstall.packages (\"ggplot2\")   \n\n# load the library ggplot2\nlibrary (\"ggplot2\")     \nTo install packages from Bioconductor, you must first install Bioconductor:\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install()\nOnce installed, you can now download packages from Bioconductor using the BiocManager::install() function. The package AnnotationDbi is one of the most used in the context of genomics. Lets install it as an example of how to install packages from the Bioconductor repository:\n# Install the package\nBiocManager::install(\"AnnotationDbi\")\n\n# Load the package\nlibrary(\"AnnotationDbi\")\nNow the functions provided by the ggplot2 and the AnnotationDbi packages are available to be used in R.\nTo install packages from GitHub, the easiest way is to install the remotes package first, and then install the package of interest.\n# Make sure you have the {remotes} installed:\ninstall.packages('remotes')\n\n# Now you can install the ualg.compbio package from GitHub with:\nremotes::install_github(\"instructr/ualg.compbio\")\nNow you will have the tutorials provided by the ualg.compbio package.\n\n\n\n\nBut how to get information/help on how to use any function in R? There are many built-in ways in which R can provide help regarding its functions and packages:\n# help(package=\"package_name\") to get help about a specific package\nhelp (package=ggplot2) \n\n# show a pdf with the package manual (called R vignettes)\nvignette (\"ggplot2\")   \n\n# ?function to get quick info about the function of interest\n?qplot  \n\n\n\n\nYour working environment is the place where the variables, functions, and data that you create are stored. More advanced users can create more than one environment.\nls()    # list all objects in your environment\ndir()   # list all files in your working directory\ngetwd() # find out the path to your working directory\nsetwd(\"/home/foo/bar/DATA/\") # example of setting a new working directory path\n\n\n\n\n\n\n\n\nTo start we will open RStudio. This is an Integrated Development Environment - IDE - that includes syntax-highlighting text editor (1 in Figure1), an R console to execute code (2 in Figure1), as well as workspace and history management (3 in Figure1), and tools for plotting and exporting images, browsing the workspace, managing packages and viewing html/pdf files created within RStudio (4 in Figure1).\n\n\n\nFigure 1: RStudio Graphical User Interface (GUI)\n\n\nProjects are a great functionality, easing the transition between different dataset analyses, and allowing a fast navigation to your analysis/working directory. To create a new project:\nFile &gt; New Project... &gt; New Directory &gt; New Project\nDirectory name: r-absoluteBeginners\nCreate project as a subdirectory of: ~/\n                           Browse... (directory/folder to save the workshop data)\nCreate Project\nProjects should be personalized by clicking on the menu in the right upper corner. The general options - R General - are the most important to customize, since they allow the definition of the RStudio “behavior” when the project is opened. The following suggestions are particularly useful:\nRestore .RData at startup - Yes (for analyses with +1GB of data, you should choose \"No\")\nSave .RData on exit - Ask\nAlways save history - Yes\n\n\n\nFigure 2: Customize Project\n\n\n\n\n\n\nImportant NOTE: Please create a new R Script file to save all the code you use for today’s tutorial and save it in your current working directory. Name it: r4ab_day1.R\n\n\n\nValues are assigned to named variables with an &lt;- (arrow) or an = (equal) sign. In most cases they are interchangeable, however it is good practice to use the arrow since it is explicit about the direction of the assignment. If the equal sign is used, the assignment occurs from left to right.\nx &lt;- 7     # assign the number 7 to a variable named x\nx          # R will print the value associated with variable x\n\ny &lt;- 9     # assign the number 9 to the variable y\n\nz = 3      # assign the value 3 to the variable z\n\n42 -&gt; lue  # assign the value 42 to the variable named lue\n\nx -&gt;  xx   # assign the value of x (which is the number 7) to the variable named xx\nxx         # print the value of xx\n\nmy_variable = 5   # assign the number 5 to the variable named my_variable\n\n\n\n\nAllow the direct comparison between values, and its result is always a TRUE or FALSE value:\n\n\n\nSymbol\nDescription\n\n\n\n\n==\nexactly the same (equal)\n\n\n!=\ndifferent (not equal)\n\n\n&lt;\nsmaller than\n\n\n&gt;\ngreater than\n\n\n&lt;=\nsmaller or equal\n\n\n&gt;=\ngreater or equal\n\n\n\n1 == 1   # TRUE\n1 != 1   # FALSE\nx &gt; 3    # TRUE (x is 7)\ny &lt;= 9   # TRUE (y is 9)\nmy_variable &lt; z   # FALSE (z is 3 and my_variable is 5)\n\n\n\n\nCompare logical (TRUE or FALSE) values:\n\n\n\nSymbol\nDescription\n\n\n\n\n&\nAND (vectorized)\n\n\n&&\nAND (non-vectorized/evaluates only the first value)\n\n\n|\nOR (vectorized)\n\n\n||\nOR (non-vectorized/evaluates only the first value)\n\n\n!\nNOT\n\n\n\nQUESTION: Are these TRUE, or FALSE?\nx &lt; y & x &gt; 10   # AND means that both expressions have to be true to return TRUE\nx &lt; y | x &gt; 10   # OR means that only one expression must be true to return TRUE\n!(x != y & my_variable &lt;= y)  # yet another AND example using NOT\n\n\n\n\nR makes calculations using the following arithmetic operators:\n\n\n\nSymbol\nDescription\n\n\n\n\n+\nsummation\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n^\npower\n\n\n\n3 / y   ## 0.3333333\nx * 2   ## 14\n3 - 4   ## -1\n2^z     ## 8\nmy_variable + 2   ## 7\n\n\n\n\n\n\nR has 5 basic data structures (see following figure).\n\n\n\nFigure 3: Basic R data structures.\n\n\n\n\nThe basic data structure in R is the vector, which requires all of its elements to be of the same type (e.g. all numeric; all character (text); all logical (TRUE or FALSE)).\n\n\n\n\n\n\n\nFunction\nDescription\n\n\n\n\nc\ncombine\n\n\n:\ninteger sequence\n\n\nseq\ngeneral sequence\n\n\nrep\nrepetitive patterns\n\n\n\nx &lt;- c (1,2,3,4,5,6)\nx\nclass (x)   # this function outputs the class of the object\n\ny &lt;- 10\nclass (y)\n\nz &lt;- \"a string\"\nclass (z)\n# The results are shown in the comments next to each line\n\nseq (1,6)   ## 1 2 3 4 5 6\nseq (from=100, by=1, length=5)   ## 100 101 102 103 104\n\n1:6    ## 1 2 3 4 5 6\n10:1   ## 10  9  8  7  6  5  4  3  2  1\n\nrep (1:2, 3)   ## 1 2 1 2 1 2\n\n\n\n\nMost arithmetic operations in the R language are vectorized, i.e. the operation is applied element-wise. When one operand is shorter than the other, the shortest one is recycled, i.e. the values from the shorter vector are re-used until the length of the longer vector is reached.\nPlease note that when one of the vectors is recycled, a warning is printed in the R Console. This warning is not an error, i.e. the operation has been completed despite the warning message.\n1:3 + 10:12\n\n# Notice the warning: this is recycling (the shorter vector \"restarts\" the \"cycling\")\n1:5 + 10:12\n\nx + y         # Remember that x = c(1,2,3,4,5,6) and y = 10\nc(70,80) + x\n\n\n\n\nSubsetting is one of the most powerful features of R. It is the extraction of one or more elements, which are of interest, from vectors, allowing for example the filtering of data, the re-ordering of tables, removal of unwanted data-points, etc. There are several ways of sub-setting data.\nNote: Please remember that indices in R are 1-based (see introduction).\n# Subsetting by indices\nmyVec &lt;- 1:26 ; myVec\nmyVec [1]    # prints the first value of myVec\nmyVec [6:9]  # prints the 6th, 7th, 8th, and 9th values of myVec \n\n# LETTERS is a built-in vector with the 26 letters of the alphabet\nmyLOL &lt;- LETTERS       # assign the 26 letters to the vector named myLOL\nmyLOL[c(3,3,13,1,18)]  # print the requested positions of vector myLOL\n\n#Subsetting by same length logical vectors\nmyLogical &lt;- myVec &gt; 10 ; myLogical\n# returns only the values in positions corresponding to TRUE in the logical vector\nmyVec [myLogical]\n\n\n\n\nReferring to an index by name rather than by position can make code more readable and flexible. Use the function names to attribute names to each position of the vector.\njoe &lt;- c (24, 1.70)\nnames (joe)              ## NULL\nnames (joe) &lt;- c (\"age\",\"height\")\nnames (joe)              ## \"age\"    \"height\"\njoe [\"age\"] == joe [1]   ## age   TRUE\n\nnames (myVec) &lt;- LETTERS\nmyVec\n# Subsetting by field names\nmyVec [c(\"A\", \"A\", \"B\", \"C\", \"E\", \"H\", \"M\")] ## The Fibonacci Series :o)\n\n\n\n\nSometimes we want to retain most elements of a vector, except for one or a few unwanted positions. Instead of specifying all elements of interest, it is easier to specify the ones we want to remove. This is easily done using the minus sign.\nalphabet &lt;- LETTERS\nalphabet   # print vector alphabet\nvowel.positions &lt;- c(1,5,9,15,21)\nalphabet[vowel.positions]    # print alphabet in vowel.positions\n\nconsonants &lt;- alphabet [-vowel.positions]  # exclude all vowels from the alphabet\nconsonants\n\n\n\n\nMatrices are two dimensional vectors (tables), where all columns are of the same length, and, just like one-dimensional vectors, matrices store same-type elements (e.g. all numeric; all character (text); all logical (TRUE or FALSE)). Matrices are explicitly created with the matrix function.\nIMPORTANT NOTE: R uses a column-major order for the internal linear storage of array values, meaning that first all of column 1 is stored, then all of column 2, etc. This implies that, by default, when you create a matrix, R will populate the first column, then the second, then the third, and so on until all values given to the matrix function are used. This is the default behavior of the matrix function, which can be changed via the byrow parameter (default value is set to FALSE).\nmy.matrix &lt;- matrix (1:12, nrow=3, byrow = FALSE)   # byrow = FALSE is the default (see ?matrix) \ndim (my.matrix)   # check the dimension (size) of the matrix: number of rows (first number) and number of columns (second number)\nmy.matrix         # print the matrix\n\nxx &lt;- matrix (1:12, nrow=3, byrow = TRUE)\ndim (xx)  # check if the dimensions of xx are the same as the dimensions of my.matrix\nxx        # compare my.matrix with xx and make sure you understand what is hapenning\n\n\n\n\nVery Important Note: The arguments inside the square brackets in matrices (and data.frames - see next section) are the [row_number, column_number]. If any of these is omitted, R assumes that all values are to be used: all rows, if the first value before the comma is missing; or all columns if the second value after the comma is missing.\n# Creating a matrix of characters\nmy.matrix &lt;- matrix (LETTERS, nrow = 4, byrow = TRUE) \n# Please notice the warning message (related to the \"recycling\" of the LETTERS)\n\nmy.matrix         # print the matrix\ndim (my.matrix)   # check the dimensions of the matrix\n\n# Subsetting by indices \nmy.matrix [,2]   # all rows, column 2 (returns a vector)\nmy.matrix [3,]   # row 3, all columns (returns a vector)\nmy.matrix [1:3,c(4,2)]   # rows 1, 2 and 3 from columns 4 and 2 (by this order) (returns a matrix)\n\n\n\n\nData frames are the most flexible and commonly used R data structures, used to store datasets in spreadsheet-like tables.\nIn a data.frame, usually the observations are the rows and the variables are the columns. Unlike matrices, the columns of a data frame can be vectors of different types (i.e. text, number, logical, etc, can all be stored in the same data frame). However, each column must to be of the same data type.\ndf &lt;- data.frame (type=rep(c(\"case\",\"control\"),c(2,3)),time=rnorm(5))  \n# rnorm is a random number generator retrieved from a normal distribution\n\nclass (df)   ## \"data.frame\"\ndf\n\n\n\n\nData frames are easily subset by index number using the square brackets notation [], or by column name using the dollar sign $.\nRemember: The arguments inside the square brackets, just like in matrices, are the [row_number, column_number]. If any of these is omitted, R assumes that all values are to be used.\nNOTE: R includes a package in its default base installation, named “The R Datasets Package”. This resource includes a diverse group of datasets, containing data from different fields: biology, physics, chemistry, economics, psychology, mathematics. These data are very useful to learn R. For more info about these datasets, run the following command: library(help=datasets)\nHere we will use the classic iris dataset to explore data frames, and learn how to subset them.\n# Familiarize yourself with the iris dataset (built-in dataset with measurements of iris flowers)\niris\n\n# Subset by indices the iris dataset\niris [,3]   # all rows, column 3 \niris [1,]   # row 1, all columns\niris [1:9, c(3,4,1,2)]   # rows 1 to 9 with columns 3, 4, 1 and 2 (in this order)\n\n# Subset by column name (for data.frames)\niris$Species            #show only the species column\niris[,\"Sepal.Length\"]\n\n# Select the time column from the df data frame created above\ndf$time      ## 0.5229577 0.7732990 2.1108504 0.4792064 1.3923535\n\n\n\n\nLists are very powerful data structures, consisting of ordered sets of elements, that can be arbitrary R objects (vectors, strings, functions, etc), and heterogeneous, i.e. each element of a different type.\nlst = list (a=1:3, b=\"hello\", fn=sqrt)   # index 3 contains the function \"square root\"\nlst\nlst$fn(49)   # outputs the square root of 49\n\n\n\n\nLike data frames they can be subset both by index number (inside square brackets) or by name using the dollar sign.\nNOTE: There is one subsetting feature that is particular to lists, which is the possibility of indexing using single square brackets [ ], or double square-brackets [[ ]]. The difference between these are the fact that, single brackets always return a list, while double brackets return the object in its native type (the same occurs with the dollar sign). For example, if the 3rd element of my.list is a data frame, then indexing the list using my.list[3] will return a list, of size 1 storing a data frame; but indexing it using my.list[[3]] will return the data frame itself.\n# Subsetting by indices\nlst [1]     # returns a list with the data contained in position 1 (preserves the type of data as list)\nclass (lst[1])\n\nlst [[1]]   # returns the data contained in position 1 (simplifies to inner data type) \nclass(lst[[1]])\n\n# Subsetting by name\nlst$b       # returns the data contained in position 1 (simplifies to inner data type)\nclass(lst$b)\n\n# Compare the class of these alternative indexing by name\nlst[\"a\"]\nlst[[\"a\"]]\n\n\n\n\nFactors are variables in R which take on a limited number of different values - such variables are often refered to as categorical variables.\n\n\n“One of the most important uses of factors is in statistical modeling; since categorical variables enter into statistical models differently than continuous variables, storing data as factors insures that the modeling functions will treat such data correctly.\nFactors in R are stored as a vector of integer values with a corresponding set of character values to use when the factor is displayed. The factor function is used to create a factor. The only required argument to factor is a vector of values which will be returned as a vector of factor values. Both numeric and character variables can be made into factors, but a factor’s levels will always be character values. You can see the possible levels for a factor through the levels command.\nFactors represent a very efficient way to store character values, because each unique character value is stored only once, and the data itself is stored as a vector of integers. Because of this, read.table will automatically convert character variables to factors unless the stringsAsFactors = FALSE argument is specified.”\n(Adapted from: https://www.stat.berkeley.edu/~s133/factors.html)\n# Create a vector of numbers to be displayed as Roman Numerals\nmy.fdata &lt;- c(1,2,2,3,1,2,3,3,1,2,3,3,1)\n# look at the vector\nmy.fdata\n\n# turn the data into factors\nfactor.data &lt;- factor(my.fdata)\n# look at the factors\nfactor.data\n\n# add labels to the levels of the data\nlabeled.data &lt;- factor(my.fdata,labels=c(\"I\",\"II\",\"III\"))\n# look at the factors\nlabeled.data\n# look only at the levels (i.e. character labels) of the factors\nlevels(labeled.data)\n\n\n\nData structures can be inter-converted (coerced) from one type to another. Sometimes it is useful to convert between data structure types (particularly when using packages).\nNOTE: Such conversions are not always possible without information loss - for example converting a data frame with mix data types to a matrix is not possible without converting all columns to the same type, possibly leading to losses.\nR has several functions for data structure conversions:\n# To check the class of the object:\nclass(lst)\n\n# To check the basic structure of an object:\nstr(lst)\n\n# \"Force\" the object to be of a certain type:\n # (this is not valid code, just a syntax example)\nas.matrix (myDataFrame)  # convert a data frame into a matrix\nas.numeric (myChar)      # convert text characters into numbers\nas.data.frame (myMatrix) # convert a matrix into a data frame\nas.character (myNumeric) # convert numbers into text chars\n\n\n\n\n\n\n\nR allows the implementation of loops, i.e. replicating instructions in an iterative way (also called cycles). The most common ones are for () loops and while () loops. The syntax for these loops is: for (condition) { code-block } and while (condition) { code-block }.\n# creating a for loop to calculate the first 12 values of the Fibonacci sequence\nmy.x &lt;- c(1,1)\nfor (i in 1:10) {\n  my.x &lt;- c(my.x, my.x[i] + my.x[i+1])\n  print(my.x)\n}\n\n# while loops will execute a block of commands until a condition is no longer satisfied\nx &lt;- 3 ; x\nwhile (x &lt; 9)\n{\n  cat(\"Number\", x, \"is smaller than 9.\\n\") # cat is a printing function (see ?cat)\n   x &lt;- x+1\n}\n\n\n\n\nConditionals allow running commands only when certain conditions are TRUE. The syntax is: if (condition) { code-block }.\nx &lt;- -5 ; x\nif (x &gt;= 0) { print(\"Non-negative number\") } else { print(\"Negative number\") }\n # Note: The else clause is optional. If the command is run at the command-line,\n  # and there is an else clause, then either all the expressions must be enclosed\n  # in curly braces, or the else statement must be in line with the if clause.\n\n# coupled with a for loop\nx &lt;- c(-5:5) ; x\nfor (i in 1:length(x)) {\n  if (x[i] &gt; 0) {\n     print(x[i])\n  } \n  else {\n   print (\"negative number\")\n  }\n}  \n\n\n\n\nThe ifelse function combines element-wise operations (vectorized) and filtering with a condition that is evaluated. The major advantage of the ifelse over the standard if-then-else statement is that it is vectorized. The syntax is: ifelse (condition-to-test, value-for-true, value-for-false).\n# re-code gender 1 as F (female) and 2 as M (male)\ngender &lt;- c(1,1,1,2,2,1,2,1,2,1,1,1,2,2,2,2,2)\nifelse(gender == 1, \"F\", \"M\")\n\n\n\n\n\nR allows defining new functions using the function command. The syntax (in pseudo-code) is the following:\nmy.function.name &lt;- function (argument1, argument2, ...) { \n  expression1\n  expression2\n  ...\n  return (value)\n  }\nNow, lets code our own function to calculate the average (or mean) of the values from a vector:\n# Define the function\n    # Please note that the function must be declared in the script before it can be used\nmy.average &lt;- function (x) {\n  average.result &lt;- sum(x)/length(x)\n  return (average.result)\n}\n\n# Create the data vector\nmy.data &lt;- c(10,20,30)\n\n# Run the function using the vector as argument\nmy.average(my.data)\n\n# Compare with R built-in mean function\nmean(my.data)\n\n\n\n\nMost R users need to load their own datasets, usually saved as table files (e.g. Excel, or .csv files), to be able to analyse and manipulate them. After the analysis, the results need to be exported/saved (e.g. to view or use with other software).\n# Inspect the esoph built-in dataset\nesoph\ndim(esoph)\ncolnames(esoph)\n\n### Saving ###\n# Save to a file named esophData.csv the esoph R dataset, separated by commas and\n # without quotes (the file will be saved in the current working directory)\nwrite.table (esoph, file=\"esophData.csv\", sep=\",\" , quote=F)\n\n# Save to a file named esophData.tab the esoph dataset, separated by tabs and without\n # quotes (the file will be saved in the current working directory)\nwrite.table (esoph, file=\"esophData.tab\", sep=\"\\t\" , quote=F)\n\n### Loading ###\n# Load a data file into R (the file should be in the working directory)\n  # read a table with columns separated by tabs\nmy.data.tab &lt;- read.table (\"esophData.tab\", sep=\"\\t\", header=TRUE)\n # read a table with columns separated by commas\nmy.data.csv &lt;- read.csv (\"esophData.csv\", header=T)\nNote: if you want to load or save the files in directories different from the working directory, just use (inside quotes) the full path as the first argument, instead of just the file name (e.g. “/home/Desktop/r_Workshop/esophData.csv”).\n\n\n\n\n\n\n# the unique function returns a vector with unique entries only (remove duplicated elements)\nunique (iris$Sepal.Length)\n\n# length returns the size of the vector (i.e. the number of elements)\nlength (unique (iris$Sepal.Length))\n\n# table counts the occurrences of entries (tally)\ntable (iris$Species)\n\n# aggregate computes statistics of data aggregates (groups)\naggregate (iris[,1:4], by=list (iris$Species), FUN=mean, na.rm=T)\n\n# the %in% function returns the intersection between two vectors\nmonth.name [month.name %in% c(\"CCMar\",\"May\", \"Fish\", \"July\", \"September\",\"Cool\")]\n\n# merge joins data frames based on a common column (that functions as a \"key\")\ndf1 &lt;- data.frame(x=1:5, y=LETTERS[1:5]) ; df1\ndf2 &lt;- data.frame(x=c(\"Eu\",\"Tu\",\"Ele\"), y=1:6) ; df2\nmerge (df1, df2, by.x=1, by.y=2, all = TRUE)\n\n# cbind and rbind (takes a sequence of vector, matrix or data-frame arguments\n # and combine them by columns or rows, respectively)\nmy.binding &lt;- as.data.frame(cbind(1:7, LETTERS[1:7]))    # the '1' (shorter vector) is recycled\nmy.binding\nmy.binding &lt;- cbind(my.binding, 8:14)[, c(1, 3, 2)] # insert a new column and re-order them\nmy.binding\n\nmy.binding2 &lt;- rbind(seq(1,21,by=2), c(1:11))\nmy.binding2\n\n# reverse the vector\nrev (LETTERS)\n# sum and cumulative sum\nsum (1:50); cumsum (1:50)\n# product and cumulative product\nprod (1:25); cumprod (1:25)\n\n### Playing with some R built-in datasets (see library(help=datasets) )\niris   # familiarize yourself with the iris data\n\n# mean, standard deviation, variance and median \nmean (iris[,2]); sd (iris[,2]); var (iris[,2]); median (iris[,2]) \n\n# minimum, maximum, range and summary statistics\nmin (iris[,1]); max (iris[,1]); range (iris[,1]); summary (iris)\n\n# exponential, logarithm\nexp (iris[1,1:4]); log (iris[1,1:4])\n\n# sine, cosine and tangent (radians, not degrees)\nsin (iris[1,1:4]); cos (iris[1,1:4]); tan (iris[1,1:4]) \n\n# sort, order and rank the vector\nsort (iris[1,1:4]); order (iris[1,1:4]); rank (iris[1,1:4])\n\n# useful to be used with if conditionals\nany (iris[1,1:4] &gt; 2)   # ask R if there are any values higher that 2? \nall (iris[1,1:4] &gt; 2)   # ask R if all values are higher than 2\n\n# select data\nwhich (iris[1,1:4] &gt; 2)\nwhich.max (iris[1,1:4]) \n\n# subset data by values/patterns from different columns \nsubset(iris, Petal.Length &gt;= 3 & Sepal.Length &gt;= 6.5, select=c(Petal.Length, Sepal.Length, Species))\n\n\n\n\nThe esoph (Smoking, Alcohol and (O)esophageal Cancer data) built-in dataset presents 2 types of variables: continuous numerical variables (the number of cases and the number of controls), and discrete categorical variables (the age group, the tobacco smoking group and the alcohol drinking group). Sometimes it is hard to “categorize” continuous variables, i.e. to group them in specific intervals of interest, and name these groups (also called levels).\nAccordingly, imagine that we are interested in classifying the number of cancer cases according to their occurrence: frequent, intermediate and rare. This type of variable re-coding into factors is easily accomplished using the function cut(), which divides the range of x into intervals and codes the values in x according to which interval they fall.\n# subset non-contiguous data from the esoph dataset\nesoph\nsummary(esoph)\n# cancers in patients consuming more than 30 g/day of tobacco\nsubset(esoph$ncases, esoph$tobgp == \"30+\")\n# total nr of cancers in patients older than 75\nsum(subset(esoph$ncases, esoph$agegp == \"75+\"))\n\n# factorize the nr of cases in 3 levels, equally spaced,\n # and add the new column named cat_ncases, to the dataset\nesoph$cat_ncases &lt;- cut (esoph$ncases,3,labels=c(\"rare\",\"med\",\"freq\"))\nsummary(esoph)\nThe end"
  },
  {
    "objectID": "tutorial_day1_code.html",
    "href": "tutorial_day1_code.html",
    "title": "Day1",
    "section": "",
    "text": "How to import datasets into R.\n\nConduct descriptive statistics on the dataset to explore the data.\n\nBasic data visualization with histograms, boxplots, and scatterplots.\n\nHow to calculate the correlation between 2 (numerical) variables.\n\nHow to make a simple linear regression, and plot the line in the scatterplot.\n\nConduct a t-test for basic hypothesis testing.\n\nRecognize the differences between base R plotting and using the ggplots2 package.\n\n\n\n\nThe scientific experiment | Imagine that you are interested in determining the effects of a high-fat diet on gene expression. For this study, the scientists obtained data from 60 mice, where half were fed a lean-diet, and the other half a high-fat diet. All other living conditions were the same. Four weeks after, a biopsy of the mice’s liver was sequenced by RNA-seq, and all mice were weighted, and the sex and age were also recorded. The results from this analysis are saved in diet_mice_metadata.txt file, and the gene counts are in the file diet_mice_counts.xlsx.\n\n\n\nWhat is the research question? What is the hypothesis?\nHow many variables are in the study?\nWhich variable(s) are dependent? (Dependent or Response variables are the variables that we are interested in predicting or explaining.)\nWhich variable(s) are independent? (Independent or Explanatory variables are used to explain or predict the dependent variable.)\nWhich variable(s) are covariates? (Covariates are variables that are potentially related to the outcome of interest in a study, but are not the main variable under study - used to control for potential confounding factors in a study.)\nAre the “controls” appropriate? Why?"
  },
  {
    "objectID": "tutorial_day1_code.html#basic-data-analysis-lesson-1",
    "href": "tutorial_day1_code.html#basic-data-analysis-lesson-1",
    "title": "Day1",
    "section": "",
    "text": "How to import datasets into R.\n\nConduct descriptive statistics on the dataset to explore the data.\n\nBasic data visualization with histograms, boxplots, and scatterplots.\n\nHow to calculate the correlation between 2 (numerical) variables.\n\nHow to make a simple linear regression, and plot the line in the scatterplot.\n\nConduct a t-test for basic hypothesis testing.\n\nRecognize the differences between base R plotting and using the ggplots2 package.\n\n\n\n\nThe scientific experiment | Imagine that you are interested in determining the effects of a high-fat diet on gene expression. For this study, the scientists obtained data from 60 mice, where half were fed a lean-diet, and the other half a high-fat diet. All other living conditions were the same. Four weeks after, a biopsy of the mice’s liver was sequenced by RNA-seq, and all mice were weighted, and the sex and age were also recorded. The results from this analysis are saved in diet_mice_metadata.txt file, and the gene counts are in the file diet_mice_counts.xlsx.\n\n\n\nWhat is the research question? What is the hypothesis?\nHow many variables are in the study?\nWhich variable(s) are dependent? (Dependent or Response variables are the variables that we are interested in predicting or explaining.)\nWhich variable(s) are independent? (Independent or Explanatory variables are used to explain or predict the dependent variable.)\nWhich variable(s) are covariates? (Covariates are variables that are potentially related to the outcome of interest in a study, but are not the main variable under study - used to control for potential confounding factors in a study.)\nAre the “controls” appropriate? Why?"
  },
  {
    "objectID": "tutorial_day1_code.html#hands-on-exercises",
    "href": "tutorial_day1_code.html#hands-on-exercises",
    "title": "Day1",
    "section": "Hands-on exercises",
    "text": "Hands-on exercises\nWe will start by looking at the metadata file containing the variables related to each sample (i.e. each mouse): type of diet, final weight, gender, and age in months.\n\nA. Create a new project in RStudio\nStart by creating a new project in RStudio. Go to File &gt; New project, and follow the instructions.\nOnce you have are in the project folder, create a new R script file. Go to File &gt; New File &gt; R Script. A blank text file will appear above the console. Save it in your project folder with the name diet_analysis.R.\n\n\nB. Load the data and inspect it\n\nDownload the file diet_mice_metadata.txt (mice weights according to diet) from GitHub https://github.com/patterninstitute/rmind-workshop/blob/main/data/diet_mice_metadata.txt.\n\nSave the file in your current working directory where the RProject was created inside a folder named data.\n\nType the instructions inside grey boxes in pane number 2 of RStudio — the R Console. As you already know, the words after a # sign are comments not interpreted by R, so you do not need to copy them.\n\nIn the R console, you must hit enter after each command to obtain the result.\n\nIn the script file (R file), you must run the command by pressing the run button (on the top panel), or by selecting the code you want to run and pressing ctrl + enter.\n\n\nSave all your relevant/final commands (R instructions) to your script file to be available for later use.\n\n\n# Load required packages\nlibrary(tidyverse)     # to ease data wrangling and visualization\nlibrary(here)          # to help with file paths \nlibrary(RColorBrewer)  # color palettes\nlibrary(patchwork)     # combine plots in panels for figures\n\n# Load the file and save it to object mice_data\nmice_data &lt;- read.table(file=here(\"data/diet_mice_metadata.txt\"), \n                        header = TRUE,\n                        sep = \"\\t\", dec = \".\",\n                        stringsAsFactors = TRUE)\n\n\n\nC. Answer the following questions using R\n\n1. Briefly explore the dataset.\nWe should use descriptive statistics that summarize the sample data. We will use measures of central tendency — Mean, Median, and Mode —, and measures of dispersion (or variability) — Standard Deviation, Variance, Maximum, and Minimum.\n\n# Look at the data\nhead (mice_data, 10)   # Show the first 10 rows\n\n   sample_id diet weight gender age_months\n1      mus01 lean  24.02      F         19\n2      mus02 lean  21.79      F         17\n3      mus03 lean  23.90      F         20\n4      mus04 lean  11.15      M         10\n5      mus05 lean  17.73      F         15\n6      mus06 lean  12.89      M         12\n7      mus07 lean  20.12      F         16\n8      mus08 lean  23.04      F         18\n9      mus09 lean  22.84      F         19\n10     mus10 lean  18.92      M         15\n\ntail (mice_data, 10)   # Show the last 10 rows\n\n   sample_id diet weight gender age_months\n51     mus51  fat  23.75      M         18\n52     mus52  fat  21.84      M         17\n53     mus53  fat  26.60      F         20\n54     mus54  fat  21.13      M         17\n55     mus55  fat  24.20      M         19\n56     mus56  fat  30.69      M         23\n57     mus57  fat  23.99      F         18\n58     mus58  fat  19.35      M         17\n59     mus59  fat  26.37      F         22\n60     mus60  fat  28.84      M         20\n\n# View (mice_data)       # Open a tab in RStudio showing the whole table\n\n# Describe the class of each column in the dataset\nstr(mice_data)\n\n'data.frame':   60 obs. of  5 variables:\n $ sample_id : Factor w/ 60 levels \"mus01\",\"mus02\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ diet      : Factor w/ 2 levels \"fat\",\"lean\": 2 2 2 2 2 2 2 2 2 2 ...\n $ weight    : num  24 21.8 23.9 11.2 17.7 ...\n $ gender    : Factor w/ 2 levels \"F\",\"M\": 1 1 1 2 1 2 1 1 1 2 ...\n $ age_months: int  19 17 20 10 15 12 16 18 19 15 ...\n\n# Summary statistics per type of diet - min, max, median, average, standard deviation and variance \nsummary (mice_data)    # quartiles, median, mean, max and min\n\n   sample_id    diet        weight      gender   age_months   \n mus01  : 1   fat :30   Min.   :10.62   F:30   Min.   :10.00  \n mus02  : 1   lean:30   1st Qu.:19.24   M:30   1st Qu.:17.00  \n mus03  : 1             Median :22.79          Median :18.00  \n mus04  : 1             Mean   :22.43          Mean   :17.98  \n mus05  : 1             3rd Qu.:25.63          3rd Qu.:20.00  \n mus06  : 1             Max.   :34.76          Max.   :24.00  \n (Other):54                                                   \n\nsd (mice_data$weight)   # standard deviation of the weight\n\n[1] 5.085764\n\nvar(mice_data$weight)   # variance of the weight (var=sd^2)\n\n[1] 25.865\n\n# The same using tidyverse style programming\nmice_data %&gt;%\n  group_by(diet) %&gt;%\n  summarise(sd = sd(weight))\n\n# A tibble: 2 × 2\n  diet     sd\n  &lt;fct&gt; &lt;dbl&gt;\n1 fat    4.48\n2 lean   4.87\n\n\n\n\n2. How is the variable “mouse weight” distributed?\nAfter summarizing the data, we should find appropriate plots to look at it. A first approach is to look at the frequency of the mouse weight values using a histogram.\nRecall | Histograms plot the distribution of a continuous variable (x-axis), in which the data is divided into a set of intervals (or bins), and the count (or frequency) of observations falling into each bin is plotted as the height of the bar.\n\n# Histogram | binwidth = 1\nmice_data %&gt;%\n  ggplot(mapping = aes(weight)) +\n  geom_histogram(binwidth = 1, fill = \"magenta\" )\n\n\n\n# Histogram | binwidth = 1\nmice_data %&gt;%\n  ggplot(mapping = aes(weight)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\" )\n\n\n\n\n\n\n3. How is the variable “mouse weight” distributed in each diet?\nSince our data of interest is one categorical variable (type of diet), and one continuous variable (weight), a boxplot is one of the most informative.\nNote| A boxplot represents the distribution of a continuous variable. The box in the middle represents the interquartile range (IQR), which is the range of values from the first quartile to the third quartile, and the line inside the box represents the median value (i.e. the second quartile). The lines extending from the box are called whiskers, and represent the range of the data outside the box, i.e. the maximum and the minimum, excluding any outliers, which are shown as points outside the whiskers (not present in this dataset). Outliers are defined as values that are more than 1.5 times the IQR below the first quartile or above the third quartile.\n\n# Box and whiskers plot (Boxplot)\nmice_data %&gt;%\n  ggplot(mapping=(aes(x=diet,y=weight))) +\n  geom_boxplot(aes(fill=diet)) +\n  geom_jitter(width=0.1, size=2, alpha=0.6)\n\n\n\n\n\n\n4. How are the other variables distributed?\nThere are other variables in our data for each mouse that could influence the results, namely gender (categorical variable) and age (discrete variable). We should also look at these data.\n\n# Diet per gender\nmice_data %&gt;%\n  ggplot(mapping = aes(x=interaction(diet,gender),y=weight)) +\n  geom_boxplot(aes(fill=interaction(diet,gender))) +\n  geom_jitter(width=0.1, size=2, alpha=0.6)\n\n\n\n# Option: Using violin plots\nmice_data %&gt;%\n  ggplot(mapping = aes(x=interaction(diet,gender),y=weight)) +\n  geom_violin(aes(fill=interaction(diet,gender))) +\n  geom_jitter(width=0.1, size=2, alpha=0.6)\n\n\n\n# Distribution of age | Using a bar plot because the numeric variable is discrete (not continuous)\nmice_data %&gt;%\n  ggplot(mapping = aes(age_months)) +\n  geom_bar(fill = \"coral\")\n\n\n\n\n\n\n5. What is the frequency of each variable?\n\n5.1 How many measurements do we have for each gender?\n5.2 How many measurements do we have for each diet?\n5.3 How many measurements do we have for each gender in each diet?\n5.4 What if we want to know the results for each of the three variables: age, diet, and gender?\n\nWhen exploring the results of an experiment, we want to learn about the variables measured (age, gender, weight), and how many observations we have for each variable (number of females, number of males …), or combination of variables, for example, number of females in lean diet. This is easily done by using the R base function table. This function outputs a frequency table, i.e. the frequency (counts) of all combinations of the variables of interest. In tidyverse we can use dplyr::count().\n\n# How many measurements do we have for each gender (a categorical variable)\ntable(mice_data$gender)\n\n\n F  M \n30 30 \n\n# How many measurements do we have for each diet (a categorical variable)\ntable(mice_data$diet)\n\n\n fat lean \n  30   30 \n\n# How many measurements do we have for each gender in each diet? (Count the number of observations in the combination between the two categorical variables).\ntable(mice_data$diet, mice_data$gender)\n\n      \n        F  M\n  fat  10 20\n  lean 20 10\n\n# We can also use this for numerical discrete variables, like age.\n# How many measurements of each age (a discrete variable) do we have by gender? \ntable(mice_data$age_months, mice_data$gender)\n\n    \n     F M\n  10 1 1\n  12 0 2\n  14 3 0\n  15 3 2\n  16 1 0\n  17 7 5\n  18 4 5\n  19 4 3\n  20 3 4\n  21 1 3\n  22 3 3\n  23 0 1\n  24 0 1\n\n# And by diet type? \ntable(mice_data$age_months, mice_data$diet)\n\n    \n     fat lean\n  10   0    2\n  12   0    2\n  14   2    1\n  15   1    4\n  16   0    1\n  17   3    9\n  18   6    3\n  19   4    3\n  20   6    1\n  21   1    3\n  22   5    1\n  23   1    0\n  24   1    0\n\n# What if we want to know the results for each of the three variables: age, diet and gender?\n   # Using ftable instead of table to format the output in a more friendly way\nftable(mice_data$age_months, mice_data$diet, mice_data$gender)\n\n         F M\n            \n10 fat   0 0\n   lean  1 1\n12 fat   0 0\n   lean  0 2\n14 fat   2 0\n   lean  1 0\n15 fat   1 0\n   lean  2 2\n16 fat   0 0\n   lean  1 0\n17 fat   0 3\n   lean  7 2\n18 fat   2 4\n   lean  2 1\n19 fat   1 3\n   lean  3 0\n20 fat   2 4\n   lean  1 0\n21 fat   0 1\n   lean  1 2\n22 fat   2 3\n   lean  1 0\n23 fat   0 1\n   lean  0 0\n24 fat   0 1\n   lean  0 0\n\n# Doing a similar analysis, using tidyverse programming style\nmice_data %&gt;%\n  group_by(age_months, diet, gender) %&gt;%\n  count()\n\n# A tibble: 30 × 4\n# Groups:   age_months, diet, gender [30]\n   age_months diet  gender     n\n        &lt;int&gt; &lt;fct&gt; &lt;fct&gt;  &lt;int&gt;\n 1         10 lean  F          1\n 2         10 lean  M          1\n 3         12 lean  M          2\n 4         14 fat   F          2\n 5         14 lean  F          1\n 6         15 fat   F          1\n 7         15 lean  F          2\n 8         15 lean  M          2\n 9         16 lean  F          1\n10         17 fat   M          3\n# ℹ 20 more rows\n\n\n\n\n6. Is there a dependency between the age and the weight of the mice in our study?\nSuggestion: To test if two variables are correlated you can start by (1) making a scatter plot of the two variables, followed by (2) a calculation of the Pearson correlation coefficient, and finally by (3) fitting a linear model to the data to evaluate how the weight changes depending on the age of the mice.\n\n# Step1: scatter plot of age and weight to look at the data\nmice_data %&gt;%\n  ggplot(mapping = aes(x=age_months,y=weight))+\n  geom_point(aes(fill=diet), shape=21, size=2)\n\n\n\n# Step2: Calculate the Pearson coefficient of correlation (r)\nmy.correlation &lt;- cor(mice_data$weight, mice_data$age_months, method = \"pearson\")\nmy.correlation\n\n[1] 0.9539404\n\n# Step3: fit a linear model (using the function lm) and \n# draw it on the scatter plot (using the function abline)\n  # NOTE: \"weight ~ age\" can be read as \"weight is modeled as a function of age\" or \n  # \"weight is explained by age\".\n  # When using lm() for linear regression, the \"y ~ x\" formula indicates that \n  # y is the dependent variable and x is the independent variable.\n\nmy.lm &lt;- lm (mice_data$weight ~ mice_data$age_months)\nprint(summary.lm(my.lm, correlation = TRUE))\n\n\nCall:\nlm(formula = mice_data$weight ~ mice_data$age_months)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.8652 -1.2020  0.0870  0.9735  4.1722 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -6.48683    1.21060  -5.358 1.51e-06 ***\nmice_data$age_months  1.60814    0.06641  24.217  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.539 on 58 degrees of freedom\nMultiple R-squared:   0.91, Adjusted R-squared:  0.9085 \nF-statistic: 586.5 on 1 and 58 DF,  p-value: &lt; 2.2e-16\n\nCorrelation of Coefficients:\n                     (Intercept)\nmice_data$age_months -0.99      \n\n# Adding the linear model line to the scatter plot\nmice_data %&gt;%\n  ggplot(mapping = aes(x=age_months,y=weight))+\n  geom_point(aes(fill=diet), shape=21, size=2) +\n  geom_smooth(method = \"lm\", se=TRUE, color=\"grey30\") # se is the shaded confidence interval\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n7. Is the correlation between the age and the weight of the mice different for males and females?\n\n# Now making individual linear fits per diet type\nmice_data %&gt;%\n  ggplot(mapping = aes(x=age_months,y=weight))+\n  geom_point(aes(fill=gender), shape=21, size=2) +\n  geom_smooth(aes(group=gender, color=gender),method = \"lm\", se=FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n8. Is the correlation between the age and the weight of the mice different for different diets?\n\n# Now making individual linear fits per diet type\nmice_data %&gt;%\n  ggplot(mapping = aes(x=age_months,y=weight))+\n  geom_point(aes(fill=diet), shape=21, size=2) +\n  geom_smooth(aes(group=diet, color=diet),method = \"lm\", se=FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n9. Does the type of diet influence the body weight of mice?\nCan we answer this question just by looking at the plot? Are these observations compatible with a scenario where the type of diet does not influence body weight?\nHere enters hypothesis testing. In hypothesis testing, the investigator formulates a null hypothesis (H0) that usually states that there is no difference between the two groups, i.e. the observed weight differences between the two groups of mice occurred only due to sampling fluctuations (like when you repeat an experiment drawing samples from the same population). In other words, H0 corresponds to an absence of effect.\nThe alternative hypothesis (H1), just states that the effect is present between the two groups, i.e. that the samples were taken from different populations.\nHypothesis testing proceeds with using a statistical test to try and reject H0. For this experiment, we will use a T-test that compares the difference between the means of the two diet groups, yielding a p-value that we will use to decide if we reject the null hypothesis, at a 5% significance level (p-value &lt; 0.05). Meaning that, if we repeat this experiment 100 times in different mice, in 5 of those experiments we will reject the null hypothesis, even thought the null hypothesis is true.\n\n# Apply a T-test to the lean and fat diet weights \n\n### Explanation of the arguments used ###\n  # alternative=\"two.sided\" :  two-sided because we want to test any difference between the means, and not only weight gain or weight loss (in which case it would be a one-sided test)\n\n  # paired = FALSE : because we measured the weight in 2 different groups of mice (never the same individual). If we measure a variable 2 times in the same individual the data would be paired.\n\n  # var.equal = TRUE : T-tests apply to equal variance data, so we assume it is TRUE and ask R to estimate the variance (if we chose FALSE, then R uses another similar method called Welch (or Satterthwaite) approximation) \n\n# Filter lean and fat datasets\nmice_data %&gt;%\n  filter(diet == \"lean\") -&gt; lean\n\nmice_data %&gt;%\n  filter(diet == \"fat\") -&gt; fat\n\n# Apply a t-test to the data\nttest &lt;- t.test(lean$weight, fat$weight,\n                alternative=\"two.sided\", \n                paired = FALSE, \n                var.equal = TRUE)\n\n# Print the results\nttest\n\n\n    Two Sample t-test\n\ndata:  lean$weight and fat$weight\nt = -3.4197, df = 58, p-value = 0.001154\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -6.550137 -1.713197\nsample estimates:\nmean of x mean of y \n 20.36700  24.49867 \n\n\n\n\n\n10. Now that we have calculated the T-test, shall we accept or reject the null hypothesis? What are the outputs in R from the t-test?\n\n# Find the names of the output from the function t.test\nnames(ttest)\n\n [1] \"statistic\"   \"parameter\"   \"p.value\"     \"conf.int\"    \"estimate\"   \n [6] \"null.value\"  \"stderr\"      \"alternative\" \"method\"      \"data.name\"  \n\n# Extract just the p-value\nttest$p.value\n\n[1] 0.00115364\n\n\n\n\n\nFinal discussion\n\n\nTake some time to discuss the results with the other participants, and decide if H0 should be rejected or not, and how confident you are that your decision is reasonable. Can you propose solutions to improve your confidence on the results? Is the experimental design appropriate for the research question being asked? Is this experiment well controlled and balanced?"
  }
]